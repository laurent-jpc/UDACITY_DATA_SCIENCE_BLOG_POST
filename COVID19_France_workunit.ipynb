{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "PROJET/PURPOSE:\n",
    "The UDACITY DATA SCIENCE project consisting in writing a Data Science Blog Post\n",
    "It's the opportunity to dive in details in a hot topic.\n",
    "\n",
    "Considering the rebound of COVID-19 cases in France these last weeks, I decided\n",
    " to see by myself the progress of the COVID-19 in France with figures directly\n",
    " reported by the hospitals via institutional site.\n",
    " I was requested to handle this project in python, a first through a dedicated\n",
    "  Notebook. It is available here-below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "PROJECT'S TITLE\n",
    "Monitoring per department of the COVID-19 situation in France (16-Dec-2022)\n",
    "Rebound of contamination and hospitalization in the last month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# import libraries\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygal\n",
    "\n",
    "from pygal_maps_fr import maps\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# requires installing\n",
    "# https://gtk-win.sourceforge.io/home/index.php/Main/Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "DATA UNDERSTANDING - Data access:\n",
    "Data are stored in the csv file named \"COVID19_France_data.csv\". It is \n",
    " provided (below the GITHUB uploading 30Mo-limit) with \",\" used as separator.\n",
    "This csv data file is read and transpose in dataframe via the python script\n",
    " provided on GITHUB.\n",
    "\n",
    "The source web site indicates that data have been gathered along the time \n",
    "from various format and content.\n",
    "The last version of these data is available on the following web site:\n",
    "https://www.data.gouv.fr/fr/datasets/synthese-des-indicateurs-de-suivi-de-lepidemie-covid-19/\n",
    "It is mentioned that this file contains all figures of the main indicators \n",
    "related to COVID-19 in France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Load the csv data file and convert it into a pandas dataframe for further use.\n",
    "# Instruction: modify the filepath according to your workspace.\n",
    "filepath = r\"C:\\Users\\to202835\\OneDrive - ATR\\_exploitation\\formation\\2022\\Udacity_DataScience\\01_Datascience\\project_01\\workspace_1\\project_01_main_v1.2.0\\table-indicateurs-open-data-dep-2022-12-19-19h01.csv\"\n",
    "df = pd.read_csv(filepath.replace('\\\\','/'), dtype={\"date\": str, \"dep\": str,\n",
    "    'lib_dep': str, 'lib_reg': str})\n",
    "\n",
    "# data format of some labels are directly enforced from this stage to\n",
    "#  to avoid message of Low memory warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "This file contains a combination of main indicators for monitoring of the \n",
    " COVID-19 epidemic in France since 18 March 2020. Data are provided per \n",
    " department and per region of France. The file reports information related to\n",
    " COVID-19 testing campaign and patients at hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df keys: ['dep' 'date' 'reg' 'lib_dep' 'lib_reg' 'tx_pos' 'tx_incid' 'TO' 'R'\n",
      " 'hosp' 'rea' 'rad' 'dchosp' 'reg_rea' 'incid_hosp' 'incid_rea'\n",
      " 'incid_rad' 'incid_dchosp' 'reg_incid_rea' 'pos' 'pos_7j' 'cv_dose1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep</th>\n",
       "      <th>date</th>\n",
       "      <th>reg</th>\n",
       "      <th>lib_dep</th>\n",
       "      <th>lib_reg</th>\n",
       "      <th>tx_pos</th>\n",
       "      <th>tx_incid</th>\n",
       "      <th>TO</th>\n",
       "      <th>R</th>\n",
       "      <th>hosp</th>\n",
       "      <th>rea</th>\n",
       "      <th>rad</th>\n",
       "      <th>dchosp</th>\n",
       "      <th>reg_rea</th>\n",
       "      <th>incid_hosp</th>\n",
       "      <th>incid_rea</th>\n",
       "      <th>incid_rad</th>\n",
       "      <th>incid_dchosp</th>\n",
       "      <th>reg_incid_rea</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_7j</th>\n",
       "      <th>cv_dose1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>84</td>\n",
       "      <td>Ain</td>\n",
       "      <td>Auvergne et Rhône-Alpes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>84</td>\n",
       "      <td>Ain</td>\n",
       "      <td>Auvergne et Rhône-Alpes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>84</td>\n",
       "      <td>Ain</td>\n",
       "      <td>Auvergne et Rhône-Alpes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>84</td>\n",
       "      <td>Ain</td>\n",
       "      <td>Auvergne et Rhône-Alpes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.173524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dep        date  reg lib_dep                  lib_reg  tx_pos  tx_incid  \\\n",
       "0  01  2020-03-18   84     Ain  Auvergne et Rhône-Alpes     NaN       NaN   \n",
       "1  01  2020-03-19   84     Ain  Auvergne et Rhône-Alpes     NaN       NaN   \n",
       "2  01  2020-03-20   84     Ain  Auvergne et Rhône-Alpes     NaN       NaN   \n",
       "3  01  2020-03-21   84     Ain  Auvergne et Rhône-Alpes     NaN       NaN   \n",
       "\n",
       "         TO   R  hosp  rea  rad  dchosp  reg_rea  incid_hosp  incid_rea  \\\n",
       "0  0.062612 NaN     2    0    1       0       35         NaN        NaN   \n",
       "1  0.132379 NaN     2    0    1       0       79         1.0        0.0   \n",
       "2  0.155635 NaN     2    0    1       0       87         0.0        0.0   \n",
       "3  0.173524 NaN     4    0    1       0       88         3.0        0.0   \n",
       "\n",
       "   incid_rad  incid_dchosp  reg_incid_rea  pos  pos_7j  cv_dose1  \n",
       "0        NaN           NaN            NaN  NaN     NaN       NaN  \n",
       "1        0.0           0.0           44.0  NaN     NaN       NaN  \n",
       "2        1.0           0.0           16.0  NaN     NaN       NaN  \n",
       "3        0.0           0.0           15.0  NaN     NaN       NaN  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a view on the data\n",
    "print('df keys:', np.array(df.columns))\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "DATA UNDERSTANDING - Data Description:\n",
    "\n",
    "- Description of data - context:\n",
    "\n",
    "\t'date'    = date (object) when the information is given: YYYY-MM-DD;\n",
    "\t\n",
    "\t'dep'     = number (str or int)of the french department;\t\n",
    "\t\n",
    "\t'reg'     = number (int) of the french region;\n",
    "\t\n",
    "\t'lib_dep' = name (object) of the french department;\n",
    "\t\n",
    "\t'lib_reg' = name (object) of the french region.\n",
    "\n",
    "\n",
    "- Description of data - Hospital situation:\n",
    "\n",
    "\t'hosp'         = number (int) of patients currently hospitalized due to\n",
    "\t\t\t\t\t  COVID-19;\n",
    "\t\t\t\t\t  \n",
    "\t'incid_hosp'   = number (float) of new hospitalized patients in the last\n",
    "\t\t\t\t\t  24h;\n",
    "\t\t\t\t\t  \n",
    "\t'rea' is the   = number (int) of patients currently in resuscitation or\n",
    "\t\t\t\t\t  intensive care unit;\n",
    "\t\t\t\t\t  \n",
    "\t'incid_rea'    = number (float) of new patients who were admitted to the \n",
    "\t\t\t\t     resuscitation unit in the last 24h;\n",
    "\t\t\t\t\t \n",
    "\t'rad'          = cumulative number (int) of patients who where\n",
    "\t\t\t\t\t  hospitalized for COVID-19 but back to home due to \n",
    "\t\t\t\t\t  improvement of their health;\n",
    "\t\t\t\t\t  \n",
    "\t'incid_rad'    = number (float) of the patients back to home in the last\n",
    "\t\t\t\t\t  24h;\n",
    "\t\t\t\t\t  \n",
    "\t'reg_rea'       = undefined (int);\n",
    "\t\n",
    "\t'reg_incid_rea' = undefined (float).\n",
    "\t\n",
    "\n",
    "- Description of data - decease due to COVID-19:\n",
    "\n",
    "\t'dchosp'       = number (int) of decease at hospital;\n",
    "\t\n",
    "\t'incid_dchosp' = number (float) of new patients deceased at the hospital\n",
    "\t\t\t\t\t  in the last 24h.\n",
    "  \n",
    "\n",
    "- Description of data - tests:  \n",
    "  \n",
    "\t'pos'      = number (float) of people declared positive (D-3 date of \n",
    "\t             test);\n",
    "\t'pos_7j'   = number (float) of people declared positive on a week\n",
    "\t\t\t\t  (D-3 data of test);\n",
    "\t'cv_dose1' = undefined (float).\n",
    "\n",
    "\n",
    "- Description of data - COVID-19 epidemic monitoring indicators:  \n",
    "  \n",
    "\t'tx_pos'   = Positivity rate (float) is the number of people tested\n",
    "\t\t\t      positive (RT-PCR or antigenic assay) for the first time in\n",
    "\t\t\t      the last 60 days over the number of people tested (positive\n",
    "\t\t\t      or negative) on a given period, without being tested \n",
    "\t\t\t      positive in the last 60 days;\n",
    "\t\t\t\t  \n",
    "\t'tx_incid' = Incidence rate (float) is the number of people tested\n",
    "\t\t\t      positive (RT-PCR or antigenic assay) for the first time in\n",
    "\t\t\t\t  the last 60 days over the size of population; it is given\n",
    "\t\t\t\t  for 100 000 of inhabitants;\n",
    "\t\t\t\t  \n",
    "\t'TO' \t   = Occupancy rate (float) is the number of hostpitalized COVID-19\n",
    "\t\t          patients over the initial number of beds at hospital (before \n",
    "\t\t\t\t  increase of this number).\n",
    "\t\t\t\t  \n",
    "\t'R' \t   = Virus replication rate (float) is the average number of people\n",
    "\t\t\t\t  that can be contaminated by a infected person.\n",
    "\t\t\t      R>1, epidemic is spreading. R<1, epidemic is declining.\n",
    "\n",
    "Remark:\n",
    "Though 'reg_rea', 'reg_incid_rea' and 'cv_dose1' are columns available in the\n",
    " data file, they are not described into the description notes. Consequently,\n",
    " we would remove them because they are useless without their definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    " BUSINESS UNDERSTANDING:\n",
    "\n",
    " According to these data, I would propose to answer the following questions:\n",
    "\n",
    "- Question 1: What is the rate of the population per department which is\n",
    "   tested for COVID-19? According to the global health policy, it could \n",
    "   allow adjusting locally the communication for increasing test of people. \n",
    "   \n",
    "- Question 2: What is the trend of admission/discharge at the hospitals? \n",
    "   It would give a trend of hospitals occupancy per department.\n",
    "   \n",
    "- Question 3: What is the level of degradation of hospitalized COVID-19 \n",
    "   patients per department in the last 24h? It could help to quickly identify \n",
    "   where to reinforce resources for treating patients in specific department \n",
    "   when needed and increase probability to save lifes with limited means.\n",
    "   \n",
    "- Question 4: What is the evolution of the patients in intensive care and \n",
    "  dead in my department in the last days or weeks?   \n",
    "   \n",
    "- Question 5: How many people would be declared positive to the Covid-19 test\n",
    "   in the upcoming week per department according to the present situation? \n",
    "   It would help to early manage logistics of patients and health resources\n",
    "   and increase communication related to safety precaution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Analysis of the need to answer the questions:\n",
    "\t\t  \n",
    "According to Question 1, I would propose to compute the number of people tested\n",
    " for COVID-19 (positive or negative) over the size of the population, expressed\n",
    " for 100 000 inhabitants. So, to get current rate 'nb_test / pop (100 000 hab)',\n",
    " I will need last 'tx_incid' and 'tx_pos' of every department.\n",
    "\n",
    "According to Question 2, I would propose to monitor the trend of hospitals\n",
    " occupancy per department. Thus I propose to monitor the rate of Input/Output \n",
    " of patients at the hospital in the last 24h as adding new people hospitalized\n",
    " minus new people back to home and new  over the number of patients at the\n",
    " hospital: ('incid_hosp' - 'incid_rad' - 'incid_dchosp') / ('hosp' + 'rea')  \n",
    "\n",
    "According to Question 3, I would propose to monitor in the last 24h the\n",
    " degradation of health of hospitalized people and people in intensive care unit.\n",
    " Thus I propose to monitor the rate \"nb of people admitted in intensive care\n",
    " over nb of people hospitalized\" ('incid_rea' / 'incid_hosp' = 'tx_rea') and\n",
    " \"nb of decease over nb of people admitted in intensive car\" ('incid_dchosp' /\n",
    " 'incid_hosp' = 'tx_dchsop') per department.\n",
    "\n",
    "According to Question 4, I would propose to plot the evolution of the\n",
    " patients in intensive care and dead in my department along the time in the\n",
    " six last months?    \n",
    " \n",
    "According to Question 5, I would propose to build a prediction model would \n",
    " give the number of people would be declared positive to the Covid-19 test in\n",
    " the upcoming week per department according to the current sitation. Model will\n",
    " use 'pos_7j' as target according to information information of the day of report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column label          type    nb uniq  rate uniq     nb nan   rate nan     nb inf   rate inf \n",
      "dep                 object        101      0.1 %          0      0.0 %          0      0.0 % \n",
      "date                object       1007     0.99 %          0      0.0 %          0      0.0 % \n",
      "reg                  int64         18     0.02 %          0      0.0 %          0      0.0 % \n",
      "lib_dep             object        101      0.1 %          0      0.0 %          0      0.0 % \n",
      "lib_reg             object         18     0.02 %          0      0.0 %          0      0.0 % \n",
      "tx_pos             float64       4582     4.51 %       5959     5.86 %          0      0.0 % \n",
      "tx_incid           float64      50498    49.65 %       5959     5.86 %          0      0.0 % \n",
      "TO                 float64       3779     3.72 %          0      0.0 %          0      0.0 % \n",
      "R                  float64        188     0.18 %      86460    85.01 %          0      0.0 % \n",
      "hosp                 int64       1672     1.64 %          0      0.0 %          0      0.0 % \n",
      "rea                  int64        457     0.45 %          0      0.0 %          0      0.0 % \n",
      "rad                  int64      16277     16.0 %          0      0.0 %          0      0.0 % \n",
      "dchosp               int64       4927     4.84 %          0      0.0 %          0      0.0 % \n",
      "reg_rea              int64        948     0.93 %          0      0.0 %          0      0.0 % \n",
      "incid_hosp         float64        244     0.24 %        101      0.1 %          0      0.0 % \n",
      "incid_rea          float64         71     0.07 %        101      0.1 %          0      0.0 % \n",
      "incid_rad          float64        175     0.17 %        101      0.1 %          0      0.0 % \n",
      "incid_dchosp       float64         61     0.06 %        101      0.1 %          0      0.0 % \n",
      "reg_incid_rea      float64        161     0.16 %        101      0.1 %          0      0.0 % \n",
      "pos                float64       4332     4.26 %       5959     5.86 %          0      0.0 % \n",
      "pos_7j             float64      13406    13.18 %       5959     5.86 %          0      0.0 % \n",
      "cv_dose1           float64         70     0.07 %     101606     99.9 %          0      0.0 % \n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# I start by building a function that would allows me checking some \n",
    "#  charactertics of the data set per column.\n",
    "# It will help me identifying necessary processing of the raw data and\n",
    "#  checking that I produce relative appropriate data (format and value).\n",
    "\n",
    "def display_columns_info(df):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Display some information per column related to the data set\n",
    "    INPUT\n",
    "        df is the dataframe\n",
    "    OUTPUT\n",
    "        nil (only display)    \n",
    "    '''\n",
    "    # Measure length of the column's title only for presentation purpose\n",
    "    max_len = 0\n",
    "    cols = np.array(df.columns)\n",
    "    for c in cols:\n",
    "        if len(c) > max_len:\n",
    "            max_len = len(c)\n",
    "    size = max_len + 2  # I will create a regulat length for label field.\n",
    "\n",
    "    # Display information per column        \n",
    "    field_1 = \"column label\" + ' '*(size - 11)\n",
    "    field_size = 10\n",
    "    field_2 = \"      type \"\n",
    "    field_3 = \"   nb uniq  rate uniq \"\n",
    "    field_4 = \"    nb nan   rate nan \"\n",
    "    field_5 = \"    nb inf   rate inf \"\n",
    "    # Introducing the results\n",
    "    print(field_1 + field_2 + field_3 + field_4 + field_5)\n",
    "\n",
    "    # Then run along the columns to perform and give the analysis per column.\n",
    "    for col in cols:\n",
    "        # get column's type\n",
    "        col_type = df[col].dtypes\n",
    "        # get number and rate of unique values\n",
    "        values_uniq = np.array(pd.unique(df[col]))\n",
    "        nb_uniq = len(values_uniq)\n",
    "        rate_uniq = 100 * nb_uniq / df[col].shape[0]\n",
    "        # get number and rate of nan values\n",
    "        nb_nan = df[col].isna().sum()\n",
    "        rate_nan = 100 * nb_nan / df[col].shape[0]\n",
    "        # get number and rate of infinite values\n",
    "        nb_inf = 0\n",
    "        for val in df[col].values:\n",
    "            if (val == np.inf) or (val == -np.inf):\n",
    "                nb_inf += 1\n",
    "        rate_inf = 100 * nb_inf / df[col].shape[0]\n",
    "\n",
    "        # Check among 'date' values that they are all strings with a length\n",
    "        #  of 10.\n",
    "        mem_unexp_dates = []\n",
    "        msg_unexp_dates = ''\n",
    "        if col == 'date':\n",
    "            for value in values_uniq:\n",
    "                if (not isinstance(value, str)) or (len(value) != 10):\n",
    "                    mem_unexp_dates.append(value)\n",
    "            if len(mem_unexp_dates) > 0:\n",
    "                msg_unexp_dates = '\\tWrong date format: ' + str(mem_unexp_dates)\n",
    "\n",
    "        # Display result\n",
    "        dec = 2\n",
    "        print('{}{} {}{} {}{}{}{} % {}{}{}{} % {}{}{}{} % {}'.format(\n",
    "            col, ' '*(size - len(col)),\n",
    "             ' ' * (field_size - len(str(col_type))), col_type,\n",
    "            ' ' * (field_size - len(str(nb_uniq))), nb_uniq,\n",
    "            ' ' * (field_size -1 - len(str(round(rate_uniq, dec)))), round(rate_uniq, dec),\n",
    "            ' ' * (field_size - len(str(nb_nan))), nb_nan,\n",
    "            ' ' * (field_size -1 - len(str(round(rate_nan, dec)))), round(rate_nan, dec),\n",
    "            ' ' * (field_size - len(str(nb_inf))), nb_inf,\n",
    "            ' ' * (field_size -1 - len(str(round(rate_inf, dec)))), round(rate_inf, dec),\n",
    "            msg_unexp_dates)\n",
    "            )\n",
    "\n",
    "# Check of the function\n",
    "display_columns_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "Having a view on the columns' content and more specific information about their\n",
    "type and values, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "DATA pre-PROCESSING\n",
    "\n",
    "- There is only one csv data file; no need to merge several data sheets;\n",
    "\n",
    "display of the dataframe and of the report here-above show that\n",
    " pre-processing is requested to format data for further use.\n",
    "\n",
    "- There is no row or column that contains only nan values;\n",
    "  No ACTION: only for information\n",
    "\n",
    "- columns 'dep', 'date', 'lib_dep' and 'lib_reg' are defined as object while\n",
    "  I would expect to get string (like 'reg'). So it could be interesting to \n",
    "  enforce the format of these columns.\n",
    "  ACTION: DpP1\n",
    "\n",
    "- Values of 'dep' are given in string format from '01' to '32' then in\n",
    "   int format from 32 to 95 plus 971 to 976.\n",
    "   For any visualization (on map or time series), i will need to clearly be\n",
    "\table to compare dates and get values of a selected date: typically, get\n",
    "    values at the last given date (16-Dec-2022); convert dates given in\n",
    "\tstring into a format recognizable for time-series visualization.\n",
    "   All values shall be converted in string format due to presence of values\n",
    "    '2A' and '2B' rather than in int format.\n",
    "   ACTION: DpP2\n",
    "\n",
    "- Globaly, what is called rate of something is not normalized by definition.\n",
    "   Actually, we note that rates like 'tw_pos' contains numerous values high\n",
    "   above 1 for this reason.\n",
    "   NO ACTION: only for information\n",
    "\n",
    "- Irrelevant and outliers per columns:\n",
    "\n",
    "\t> Names of the french departments and regions can be removed after \n",
    "\t   creating a dictionary to find the name from the number for further use.\n",
    "\t  ACTION: DpP2\n",
    "\n",
    "\t> As a reminder from description of content of the data file, undefined\n",
    "\t  parameters 'reg_rea', 'reg_incid_rea' and 'cv_dose1' can be removed \n",
    "      because useless without a description.\n",
    "\t  ACTION: DpP3\n",
    "\t\n",
    "\t> 'tx_pos' contains values higher than 1. It contains 5.9% of nan; \n",
    "\t\t\t   I shall remove them before modeling.\n",
    "\t\t\t   ACTION: DpP4\n",
    "\t\n",
    "\t> 'tx_incid' contains 5.9% of nan; I shall remove them before modeling.\n",
    "\t\t\t\t ACTION: DpP4\n",
    "\t\n",
    "\t> 'R' contains 85% nan; we gonna remove this column since too many values\n",
    "       are missing.\n",
    "\t   ACTION: DpP3\n",
    "\t   \n",
    "\t> 'incid_hosp' contains 0.1% of nan; I shall remove them before modeling.\n",
    "\t\tACTION: DpP4\n",
    "\t\n",
    "\t> 'incid_rea' contains 0.1% of nan; I shall remove them before modeling.\n",
    "\t\tACTION: DpP4\n",
    "\t\n",
    "\t> 'incid_rad' contains 0.1% of nan; I shall remove them before modeling.\n",
    "\t\tACTION: DpP4\n",
    "\t\n",
    "\t> 'incid_dchosp' contains 0.1% of nan; I shall remove them before modeling.\n",
    "\t\tACTION: DpP4\n",
    "\t\n",
    "\t> 'reg_incid_rea' contains 0.1% of nan; I shall remove them before modeling.\n",
    "\t\tACTION: DpP4\n",
    "\t\n",
    "\t> 'pos' contains 5.9% of nan; I shall remove them before modeling.\n",
    "\t\tACTION: DpP4\n",
    "\t\n",
    "\t> 'pos_7j' contains 5.9% of nan; I shall remove them before modeling.\n",
    "\t\tACTION: DpP4\n",
    "\t\n",
    "\t> 'cv_dose1' contains 99.9% of nan; we gonna remove this column since\n",
    "       too many values are missing\n",
    "\t    ACTION: DpP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data processing - DpP1\n",
    "Enforce the format of these columns 'dep', 'region', 'lib_dep' and 'lib_reg'\n",
    " to string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg object\n",
      "dep object\n",
      "date object\n",
      "lib_reg object\n",
      "lib_dep object\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DP1 - Enforce the format of these columns 'dep', 'region', 'lib_dep' and\n",
    "#  'lib_reg' to string format.\n",
    "\n",
    "# Convert into string\n",
    "df['reg'] = df['reg'].astype(str)\n",
    "df['dep'] = df['dep'].astype(str)\n",
    "df['date'] = df['date'].astype(str)\n",
    "df['lib_reg'] = df['lib_reg'].astype(str)\n",
    "df['lib_dep'] = df['lib_dep'].astype(str)\n",
    "# Check result of conversion\n",
    "print('reg', df['reg'].dtypes)\n",
    "print('dep', df['dep'].dtypes)\n",
    "print('date', df['date'].dtypes)\n",
    "print('lib_reg', df['lib_reg'].dtypes)\n",
    "print('lib_dep', df['lib_dep'].dtypes)\n",
    "# it does not seem to have the expected effect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data processing - DpP2\n",
    "All values shall be converted in string format due to presence of values\n",
    " '2A' and '2B' rather than in int format.\n",
    "Names of the french departments and regions can be removed after \n",
    "\t   creating a dictionary to find the name from the number for further use.\n",
    "\n",
    "For visualisation, I need to convert string dates into a int value of number\n",
    " of days (timestamp). For that purpose I will split the string into the year,\n",
    " the month and the day and compute the number of passed days for every of these\n",
    " part since their 0-ref."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calender: [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DpP2 (start)\n",
    "\n",
    "# Create a kind of calendar that provide the number of cumumlated passed days\n",
    "#  at beginning of every month since beginning of the year.\n",
    "\n",
    "def get_cumul_days():\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Return a list to ease count, month per month, passed day from the\n",
    "         beginning of the year.\n",
    "    INPUT\n",
    "        nil\n",
    "    OUTPUT\n",
    "        cnt_day_at_start_month is a list that gives the nb of past days from\n",
    "         beginning of the year for every month\n",
    "    '''\n",
    "    cnt_day_at_start_month = []\n",
    "\n",
    "    day_by_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in day_by_month:\n",
    "        cnt += i \n",
    "        cnt_day_at_start_month.append(cnt)\n",
    "\n",
    "    return cnt_day_at_start_month\n",
    "\n",
    "# Chech the function\n",
    "calendar = get_cumul_days()\n",
    "print('calender:', calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 31 vs expected: 31\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Then I use this calendar to build a function that will provide the number\n",
    "#  of passed days since beginning of the year to beginning of the selected\n",
    "#  month.\n",
    "\n",
    "def get_cnt_day_at_start_month(m, calendar):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        get the number of past days from the beginning of year and at \n",
    "         beginning of the selected month.\n",
    "    INPUT\n",
    "        m is the selected month (str of int, int or float)\n",
    "        calendar is a list that gives the nb of past days from beginning of the\n",
    "                 year for every month\n",
    "    OUTPUT\n",
    "        cnt is the count of days (int) from beginning of the year at start of\n",
    "         the selected month.\n",
    "    '''\n",
    "    cnt = calendar[int(m)-1]\n",
    "    return cnt\n",
    "\n",
    "# Check the function\n",
    "# 31 days passed at beginning of february.\n",
    "print('result:', get_cnt_day_at_start_month(2, calendar), 'vs expected:', 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: [738695, 1] vs computed [738695      1]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Finally, I compute a timestamp from the dates as the number of days passed \n",
    "#  from 0 to the selected day such as for instances:\n",
    "# 2022-06-24 => 2022 * nb_days_passed_to_this_year from year 0\n",
    "#             + number_passed_days_from_beginning_of_the_year_to_beginning_of\n",
    "#               this_month\n",
    "#             + 24 (number of days passed since beginning of the month)\n",
    "#             = 2022 * 365.24219 + 151 + 24 = 738695\n",
    "# 0000-01-01 = 0 + 0 + 1 = 1\n",
    "\n",
    "\n",
    "def get_timestamp_array(dates_str):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Convert an np.array of dates in string format\n",
    "        to a timestamp in number of days.\n",
    "    INPUT\n",
    "        dates_str is a np.array of dates YYYY-MM-DD in string format\n",
    "    OUTPUT\n",
    "        timestamp is np.array with data converted in number of days (int)\n",
    "    '''\n",
    "    timestamp = []\n",
    "    j = 0\n",
    "    for d in dates_str:\n",
    "        try:\n",
    "            y = float(d[:4])\n",
    "            m = float(d[5:7])\n",
    "            d = float(d[8:10])\n",
    "            # convert the data in number of days\n",
    "            cnt_days_for_months = float(get_cnt_day_at_start_month(m, calendar))\n",
    "            ts = y * 365.24219 + cnt_days_for_months + d\n",
    "        except:\n",
    "            ts = 0.0\n",
    "        ts_r = round(ts, 0)\n",
    "        timestamp.append(int(ts_r))\n",
    "        j += 1\n",
    "    return np.array(timestamp)\n",
    "\n",
    "test_dates = np.array(['2022-06-24', '0000-01-01'])\n",
    "timestamp_arr = get_timestamp_array(test_dates)\n",
    "print('expected: {} vs computed {}'.format([738695, 1], timestamp_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department dictionary:\n",
      " {'01': 'Ain', '02': 'Aisne', '03': 'Allier', '04': 'Alpes-de-Haute-Provence', '05': 'Hautes-Alpes', '06': 'Alpes-Maritimes', '07': 'Ardèche', '08': 'Ardennes', '09': 'Ariège', '10': 'Aube', '11': 'Aude', '12': 'Aveyron', '13': 'Bouches-du-Rhône', '14': 'Calvados', '15': 'Cantal', '16': 'Charente', '17': 'Charente-Maritime', '18': 'Cher', '19': 'Corrèze', '21': \"Côte-d'Or\", '22': \"Côtes-d'Armor\", '23': 'Creuse', '24': 'Dordogne', '25': 'Doubs', '26': 'Drôme', '27': 'Eure', '28': 'Eure-et-Loir', '29': 'Finistère', '2A': 'Corse-du-Sud', '2B': 'Haute-Corse', '30': 'Gard', '31': 'Haute-Garonne', '32': 'Gers', '33': 'Gironde', '34': 'Hérault', '35': 'Ille-et-Vilaine', '36': 'Indre', '37': 'Indre-et-Loire', '38': 'Isère', '39': 'Jura', '40': 'Landes', '41': 'Loir-et-Cher', '42': 'Loire', '43': 'Haute-Loire', '44': 'Loire-Atlantique', '45': 'Loiret', '46': 'Lot', '47': 'Lot-et-Garonne', '48': 'Lozère', '49': 'Maine-et-Loire', '50': 'Manche', '51': 'Marne', '52': 'Haute-Marne', '53': 'Mayenne', '54': 'Meurthe-et-Moselle', '55': 'Meuse', '56': 'Morbihan', '57': 'Moselle', '58': 'Nièvre', '59': 'Nord', '60': 'Oise', '61': 'Orne', '62': 'Pas-de-Calais', '63': 'Puy-de-Dôme', '64': 'Pyrénées-Atlantiques', '65': 'Hautes-Pyrénées', '66': 'Pyrénées-Orientales', '67': 'Bas-Rhin', '68': 'Haut-Rhin', '69': 'Rhône', '70': 'Haute-Saône', '71': 'Saône-et-Loire', '72': 'Sarthe', '73': 'Savoie', '74': 'Haute-Savoie', '75': 'Paris', '76': 'Seine-Maritime', '77': 'Seine-et-Marne', '78': 'Yvelines', '79': 'Deux-Sèvres', '80': 'Somme', '81': 'Tarn', '82': 'Tarn-et-Garonne', '83': 'Var', '84': 'Vaucluse', '85': 'Vendée', '86': 'Vienne', '87': 'Haute-Vienne', '88': 'Vosges', '89': 'Yonne', '90': 'Territoire de Belfort', '91': 'Essonne', '92': 'Hauts-de-Seine', '93': 'Seine-Saint-Denis', '94': 'Val-de-Marne', '95': \"Val-d'Oise\", '971': 'Guadeloupe', '972': 'Martinique', '973': 'Guyane', '974': 'Réunion', '976': 'Mayotte'}\n",
      "Region dictionary:\n",
      " {'84': 'Auvergne et Rhône-Alpes', '32': 'Hauts-de-France', '93': \"Provence-Alpes-Côte d'Azur\", '44': 'Grand Est', '76': 'Occitanie', '28': 'Normandie', '75': 'Nouvelle Aquitaine', '24': 'Centre-Val de Loire', '27': 'Bourgogne et Franche-Comté', '53': 'Bretagne', '94': 'Corse', '52': 'Pays de la Loire', '11': 'Île-de-France', '1': 'Guadeloupe', '2': 'Martinique', '3': 'Guyane', '4': 'Réunion', '6': 'Mayotte'}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# I would like to present results per department or per region.  I will build a dictionary\n",
    "# to be able to link id of a department to the name of a department.\n",
    "# I build a function to be able to get a dictionary either of department or \n",
    "#  for region. Then, I will add a function specially for department.\n",
    "\n",
    "def get_area_names(df, aera_id_label:str, aera_name_label: str):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        build a dictionary of a type or area (department or region) allowing\n",
    "         getting a name of this area from its id\n",
    "    INPUT\n",
    "        df is the globale dataframe\n",
    "        aera_id_label is the id (str) of the area: 'dep' (department) or\n",
    "         'reg' (region)\n",
    "        area_name_label is the name (str) of the area: 'lib_dep' (department)\n",
    "         or 'lib_reg' (region)\n",
    "    OUTPUT\n",
    "        dict_areas is a dictionary: id is the key, name is the value\n",
    "    '''\n",
    "\n",
    "    dict_areas = dict()\n",
    "    # get the list of area id and related names\n",
    "    area_ids = np.array(df[aera_id_label])\n",
    "    area_names = np.array(df[aera_name_label])\n",
    "    area_id_uniq = []\n",
    "    for i, area_id in enumerate(area_ids):\n",
    "        if area_id not in area_id_uniq:\n",
    "            area_id_uniq.append(area_id)\n",
    "            dict_areas[area_id] = area_names[i]\n",
    "        else:\n",
    "            pass\n",
    "    del df, aera_id_label, aera_name_label, area_ids, area_names, area_id_uniq\n",
    "    return dict_areas\n",
    "\n",
    "# Check the function\n",
    "# - Get a dictionary of departments\n",
    "dict_lib_dep = get_area_names(df, 'dep', 'lib_dep')\n",
    "print('Department dictionary:\\n', dict_lib_dep)\n",
    "# - Get a dictionary of regions\n",
    "dict_lib_reg = get_area_names(df, 'reg', 'lib_reg')\n",
    "print('Region dictionary:\\n', dict_lib_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loiret: Loiret - Loiret - Loiret - unknown\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Then I build a function dedicated to the identification of a name of the\n",
    "#  department according to its id. \n",
    "\n",
    "def get_dep_name(dep_id):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        give the name of a department in accordance with its id\n",
    "    INPUT\n",
    "        dep_id is the id (str, int or float) of the department from which we want the name\n",
    "    OUTPUT\n",
    "        dep_name is the name (str) of the department related to the given id\n",
    "    '''\n",
    "    if type(dep_id) != 'str':\n",
    "        if type(dep_id) == float:\n",
    "            dep_id = int(round(dep_id, 0))\n",
    "        dep_id = str(dep_id)  # Ids must be string in accordance with the file\n",
    "                              #  notably due to presence of deps 2A and 2B.\n",
    "        if len(dep_id) == 1:\n",
    "            dep_id = '0' + dep_id\n",
    "    try:\n",
    "        name = dict_lib_dep[dep_id]\n",
    "    except:\n",
    "        name = 'unknown'\n",
    "    return name\n",
    "\n",
    "# Check the function with various formats\n",
    "t_str = get_dep_name('45')\n",
    "t_int = get_dep_name(45)\n",
    "t_float = get_dep_name(float(45.0))\n",
    "t_unk = get_dep_name('604')\n",
    "print('Loiret: {} - {} - {} - {}'.format(t_str, t_int, t_float, t_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provence-Alpes-Côte d'Azur: Provence-Alpes-Côte d'Azur - Provence-Alpes-Côte d'Azur - Provence-Alpes-Côte d'Azur - unknown\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Then I build a function dedicated to the identification of a name of the\n",
    "#  region according to its id. \n",
    "\n",
    "def get_reg_name(reg_id):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        give the name of a region in accordance with its id\n",
    "    INPUT\n",
    "        reg_id is the id (str, int or float) of the region from which we want the name\n",
    "    OUTPUT\n",
    "        reg_name is the name (str) of the region related to the given id\n",
    "    '''\n",
    "    if type(reg_id) != 'str':\n",
    "        if type(reg_id) == float:\n",
    "            reg_id = int(round(reg_id, 0))\n",
    "        reg_id = str(reg_id)  # Ids must be string in accordance with the file\n",
    "    try:\n",
    "        name = dict_lib_reg[reg_id]\n",
    "    except:\n",
    "        name = 'unknown'\n",
    "    return name\n",
    "\n",
    "# Check the function with various formats\n",
    "t_str = get_reg_name('93')\n",
    "t_int = get_reg_name(93)\n",
    "t_float = get_reg_name(float(93.0))\n",
    "t_unk = get_reg_name('604')\n",
    "print(\"Provence-Alpes-Côte d'Azur: {} - {} - {} - {}\".format(t_str, t_int, t_float, t_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: ['Loiret', \"Côte-d'Or\"] vs computed: ['Loiret', \"Côte-d'Or\"]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Then by extension, I build a function to provide the name of departments from\n",
    "#  a list of their ids.\n",
    "\n",
    "def get_dep_names(dep_ids: list):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        give a list of department names according to a list of department ids\n",
    "    INPUT\n",
    "        dep_ids is the list of department id\n",
    "    OUTPUT\n",
    "        dep_names is the list of department names\n",
    "    '''\n",
    "    dep_names = list()\n",
    "    for dep_id in dep_ids:\n",
    "        dep_names.append(get_dep_name(dep_id))\n",
    "\n",
    "    return dep_names\n",
    "\n",
    "# Check the function\n",
    "list_dep_ids = [45, '21']\n",
    "print('expected: {} vs computed: {}'.format(['Loiret', \"Côte-d'Or\"], get_dep_names(list_dep_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: ['Occitanie', 'Bourgogne et Franche-Comté'] vs computed: ['Occitanie', 'Bourgogne et Franche-Comté']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# In the same way, I build a function to provide the name of region from\n",
    "#  a list of their ids.\n",
    "\n",
    "def get_reg_names(reg_ids: list):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        give a list of region names according to a list of region ids\n",
    "    INPUT\n",
    "        reg_ids is the list of region id\n",
    "    OUTPUT\n",
    "        reg_names is the list of region names\n",
    "    '''\n",
    "    reg_names = list()\n",
    "    for reg_id in reg_ids:\n",
    "        reg_names.append(get_reg_name(reg_id))\n",
    "\n",
    "    return reg_names\n",
    "\n",
    "#  Check the function\n",
    "list_reg_ids = [76, '27']\n",
    "print('expected: {} vs computed: {}'.format(['Occitanie', 'Bourgogne et Franche-Comté'], get_reg_names(list_reg_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data processing - DpP3\n",
    "Remove following columns from the dataframe df:\n",
    " 'reg_rea', 'reg_incid_rea', 'cv_dose1', 'R', 'cv_dose1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df's size has changed from (101707, 22) to (101707, 16):\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DpP3\n",
    "\n",
    "# remove useless or incomplete columns:\n",
    "size_before = df.shape\n",
    "df.drop(columns=['reg_rea', 'reg_incid_rea', 'cv_dose1', 'R', 'lib_dep', 'lib_reg'], inplace=True)\n",
    "\n",
    "# check result of the action:\n",
    "print(\"df's size has changed from {} to {}:\".format(size_before, df.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data processing - DpP4\n",
    "Remove empty/invalid rows from following columns from the dataframe used for\n",
    " modeling:\n",
    " 'tx_pos', 'tx_incid', 'incid_hosp', 'incid_rea', 'incid_rad', 'incid_dchosp',\n",
    " 'reg_incid_rea', 'pos', 'pos_7j'.\n",
    "By principle, any row containing a nan or infinite value shall be removed\n",
    " from the dataframe used for modeling to work on a clean set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column label         type    nb uniq  rate uniq     nb nan   rate nan     nb inf   rate inf \n",
      "dep                object        101     0.11 %          0      0.0 %          0      0.0 % \n",
      "date               object        948     0.99 %          0      0.0 %          0      0.0 % \n",
      "reg                object         18     0.02 %          0      0.0 %          0      0.0 % \n",
      "tx_pos            float64       4581     4.78 %          0      0.0 %          0      0.0 % \n",
      "tx_incid          float64      50497    52.74 %          0      0.0 %          0      0.0 % \n",
      "TO                float64       3548     3.71 %          0      0.0 %          0      0.0 % \n",
      "hosp                int64       1548     1.62 %          0      0.0 %          0      0.0 % \n",
      "rea                 int64        402     0.42 %          0      0.0 %          0      0.0 % \n",
      "rad                 int64      16209    16.93 %          0      0.0 %          0      0.0 % \n",
      "dchosp              int64       4920     5.14 %          0      0.0 %          0      0.0 % \n",
      "incid_hosp        float64        203     0.21 %          0      0.0 %          0      0.0 % \n",
      "incid_rea         float64         57     0.06 %          0      0.0 %          0      0.0 % \n",
      "incid_rad         float64        165     0.17 %          0      0.0 %          0      0.0 % \n",
      "incid_dchosp      float64         41     0.04 %          0      0.0 %          0      0.0 % \n",
      "pos               float64       4331     4.52 %          0      0.0 %          0      0.0 % \n",
      "pos_7j            float64      13405     14.0 %          0      0.0 %          0      0.0 % \n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DpP4\n",
    "\n",
    "# I remove all rows containing at least one nan (loose 5.9% of the series)\n",
    "df.dropna(axis='index', how='any', inplace=True)\n",
    "\n",
    "# Check result of the action\n",
    "display_columns_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "PREPARE DATA FOR ANALYSIS\n",
    "\n",
    "Data post-processing:\n",
    "\n",
    "From this point, I will add new columns with computed values. Result of these\n",
    " computations may generate nan or infinite values. For this purpose, I propose\n",
    " to process computed valued after their computation to remove these unexpected\n",
    " values.\n",
    "ACTION: DPP0\n",
    "\n",
    "\n",
    "According to Question 1, I compute a rate 'nb_test / pop (100 000 hab)',\n",
    "  dividing 'tx_pos' by 'tx_incid' (nb_positive/nb_test over\n",
    " nb_positive/nb_pop). Then I get a 'rate' which is the nb of people tested \n",
    " for COVID-19 (positive or negative) over the size of the population, given\n",
    " for 100 000 inhabitants. I call the result column 'tx_test'.\n",
    "ACTION: DPP1\n",
    " \n",
    "\n",
    "According to Question 2, I compute the Rate of Patient-Input/Output at\n",
    " hospital as\n",
    " ('incid_hosp' - 'incid_rad' - 'incid_dchosp') / ('hosp' + 'rea') \n",
    "When necessary, I replace the sum of 'hosp' + 'rea' (denominator) by 1 when\n",
    " it equals to zero to be able to show the change. Actually, there is not a\n",
    " big difference in this context between zero people.\n",
    "ACTION: DPP2\n",
    " \n",
    "For this both operations, it helps to replace nan by 0 and inf values by \n",
    "the maximum of the numeric values to provide a reasonable finite a high\n",
    "value instead of infinite. This is the purpose of ACTION DPP1.\n",
    "\n",
    "\n",
    "According to Question 3, I compute both rates to monitor in the last 24h \n",
    "  the degradation of health of hospitalized people and people in intensive\n",
    "  care unit as follows:\n",
    "- Rate of people admitted in intensive care over people hospitalized:\n",
    "   'incid_rea' / 'incid_hosp' = 'tx_rea'\n",
    "- Rate of deceases at hospital over people admitted in intensive care:\n",
    "   'incid_dchosp' / 'incid_rea' = 'tx_dchsop' \n",
    "ACTION: DPP3\n",
    "\n",
    "For this both operations, it helps to replace nan by 0 and inf values by \n",
    "the maximum of the numeric values to provide a reasonable finite a high\n",
    "value instead of infinite. This is the purpose of ACTION DPP1.\n",
    "\n",
    "\n",
    "According to Question 4, there is no computation to perform. Nevertheless, \n",
    "there is a bit of preparation to capture the appropriate timeseries.\n",
    "I propose to display data on the last 30 weeks, both hospitalizations and \n",
    "deceases in the same plot using the same axis to keep ratio between both.\n",
    "ACTION: DPP4\n",
    "\n",
    "According to Question 5, I built a prediction model to give 'pos_7j' as target\n",
    " according to other information, except the date because I would appreciate a\n",
    " situation only regarding the other figures with dependencies with the time.\n",
    " For the occasion I create a dataframe as a copy of the current dataframe.\n",
    " Thus I can apply additional processing to the dataframe dedicated to data\n",
    " modelization.\n",
    " It may be considered to test applying dummy values to model to identify the \n",
    "  impact and decide if it brings better result or not. According to this result\n",
    "  dummy values will be or not maintain in the dataframe for modeling.\n",
    "  If no dummy is used, columns with string shall be removed (due to the use\n",
    "  of a Linear Regression model that does not support string).\n",
    "ACTION: DPP5: it consists in:\n",
    "- After DPP0, I have a dataframe specific for modeling.\n",
    "- Add dummies to the specific dataframe (not activated here)\n",
    "- Remove columns not compatible with modeling (str vs Linear Regression)\n",
    "- Define the target (response) of the model\n",
    "- split the dataset into explanatory and response data sets\n",
    "- Get a trained model\n",
    "- Check performance of the model (into the visualization section)\n",
    "\n",
    "CAUTION! I shall make a copy of the cleaned dataframe for modeling before\n",
    " adding new columns.\n",
    "ACTION: DPP6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data Post-processing DPP6\n",
    "copy the dataframe for further modeling without new computed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Data Post-processing DPP6\n",
    "\n",
    "# Copy df for modeling\n",
    "df_lin = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data Post-processing DPP0\n",
    "It consist to build a function to clean the data set from unexpected values\n",
    " (nan, infinite) from the new computed data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DDP0\n",
    "# This function allows removing unexpected values from new computed columns.\n",
    "\n",
    "def replace_invalid_data(df, label):\n",
    "    '''\n",
    "    DESCRIPtION\n",
    "        Replace invalid data like nan or infinite by values\n",
    "    INPUT\n",
    "        df is the dataframe to work on\n",
    "        label of the category (string) where invalid data will be replaced\n",
    "    OUTPUT\n",
    "        df is the dataframe modified\n",
    "    '''\n",
    "    # Replace nan values by 0\n",
    "    df[label] = df[label].fillna(0)\n",
    "\n",
    "    # Replace infinite (inf) values by the maximum of the serie\n",
    "    maxi = df[label].max()\n",
    "    df[label].replace([np.inf, -np.inf], maxi, inplace=True)  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data Post-processing DPP1\n",
    "\n",
    "Compute the new column 'tx_test' ('nb_test / pop (100 000 hab)') as the result\n",
    " dividing 'tx_pos' by 'tx_incid' (nb_positive/nb_test over nb_positive/nb_pop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep</th>\n",
       "      <th>date</th>\n",
       "      <th>reg</th>\n",
       "      <th>tx_pos</th>\n",
       "      <th>tx_incid</th>\n",
       "      <th>TO</th>\n",
       "      <th>hosp</th>\n",
       "      <th>rea</th>\n",
       "      <th>rad</th>\n",
       "      <th>dchosp</th>\n",
       "      <th>incid_hosp</th>\n",
       "      <th>incid_rea</th>\n",
       "      <th>incid_rad</th>\n",
       "      <th>incid_dchosp</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_7j</th>\n",
       "      <th>tx_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>84</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.400716</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>315</td>\n",
       "      <td>88</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.934307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>84</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.377460</td>\n",
       "      <td>137</td>\n",
       "      <td>8</td>\n",
       "      <td>318</td>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.846715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>84</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>323</td>\n",
       "      <td>89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.534286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>84</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>134</td>\n",
       "      <td>6</td>\n",
       "      <td>325</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.477143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>84</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>133</td>\n",
       "      <td>6</td>\n",
       "      <td>326</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.465714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dep        date reg  tx_pos  tx_incid        TO  hosp  rea  rad  dchosp  \\\n",
       "56  01  2020-05-13  84    2.65      1.37  0.400716   139    8  315      88   \n",
       "57  01  2020-05-14  84    2.32      2.74  0.377460   137    8  318      88   \n",
       "58  01  2020-05-15  84    1.87      3.50  0.366726   135    7  323      89   \n",
       "59  01  2020-05-16  84    1.67      3.50  0.338104   134    6  325      90   \n",
       "60  01  2020-05-17  84    1.63      3.50  0.338104   133    6  326      90   \n",
       "\n",
       "    incid_hosp  incid_rea  incid_rad  incid_dchosp  pos  pos_7j   tx_test  \n",
       "56         6.0        0.0        4.0           0.0  9.0     9.0  1.934307  \n",
       "57         4.0        0.0        4.0           0.0  9.0    18.0  0.846715  \n",
       "58         4.0        0.0        5.0           1.0  5.0    23.0  0.534286  \n",
       "59         1.0        0.0        2.0           1.0  0.0    23.0  0.477143  \n",
       "60         1.0        0.0        1.0           0.0  0.0    23.0  0.465714  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DPP1 for answering Question 1\n",
    "\n",
    "# Create a column with the result of 'tx_pos' / 'tx_incid' = tx_test\n",
    "df['tx_test'] = df['tx_pos'].div(df['tx_incid'])  # div function allows supporting \n",
    "                                                  #  missing value (in case we miss\n",
    "                                                  #  something) with fill_value\n",
    "# Replace invalid data\n",
    "df = replace_invalid_data(df, 'tx_test')\n",
    "\n",
    "# Check the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column label         type    nb uniq  rate uniq     nb nan   rate nan     nb inf   rate inf \n",
      "dep                object        101     0.11 %          0      0.0 %          0      0.0 % \n",
      "date               object        948     0.99 %          0      0.0 %          0      0.0 % \n",
      "reg                object         18     0.02 %          0      0.0 %          0      0.0 % \n",
      "tx_pos            float64       4581     4.78 %          0      0.0 %          0      0.0 % \n",
      "tx_incid          float64      50497    52.74 %          0      0.0 %          0      0.0 % \n",
      "TO                float64       3548     3.71 %          0      0.0 %          0      0.0 % \n",
      "hosp                int64       1548     1.62 %          0      0.0 %          0      0.0 % \n",
      "rea                 int64        402     0.42 %          0      0.0 %          0      0.0 % \n",
      "rad                 int64      16209    16.93 %          0      0.0 %          0      0.0 % \n",
      "dchosp              int64       4920     5.14 %          0      0.0 %          0      0.0 % \n",
      "incid_hosp        float64        203     0.21 %          0      0.0 %          0      0.0 % \n",
      "incid_rea         float64         57     0.06 %          0      0.0 %          0      0.0 % \n",
      "incid_rad         float64        165     0.17 %          0      0.0 %          0      0.0 % \n",
      "incid_dchosp      float64         41     0.04 %          0      0.0 %          0      0.0 % \n",
      "pos               float64       4331     4.52 %          0      0.0 %          0      0.0 % \n",
      "pos_7j            float64      13405     14.0 %          0      0.0 %          0      0.0 % \n",
      "tx_test           float64      91399    95.46 %          0      0.0 %          0      0.0 % \n"
     ]
    }
   ],
   "source": [
    "# Test values of the result\n",
    "display_columns_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data Post-processing DPP2\n",
    "\n",
    "Compute 'tx_incid_IO' as the rate of Patient-Input/Output at hospital as\n",
    " ('incid_hosp' - 'incid_rad' - 'incid_dchosp') / ('hosp' + 'rea') \n",
    "When necessary, I replace the sum of 'hosp' + 'rea' (denominator) by 1 when\n",
    " it equals to zero to be able to show the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep</th>\n",
       "      <th>date</th>\n",
       "      <th>reg</th>\n",
       "      <th>tx_pos</th>\n",
       "      <th>tx_incid</th>\n",
       "      <th>TO</th>\n",
       "      <th>hosp</th>\n",
       "      <th>rea</th>\n",
       "      <th>rad</th>\n",
       "      <th>dchosp</th>\n",
       "      <th>incid_hosp</th>\n",
       "      <th>incid_rea</th>\n",
       "      <th>incid_rad</th>\n",
       "      <th>incid_dchosp</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_7j</th>\n",
       "      <th>tx_test</th>\n",
       "      <th>tx_incid_IO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>84</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.400716</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>315</td>\n",
       "      <td>88</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.934307</td>\n",
       "      <td>0.013605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>84</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.377460</td>\n",
       "      <td>137</td>\n",
       "      <td>8</td>\n",
       "      <td>318</td>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>84</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>323</td>\n",
       "      <td>89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.534286</td>\n",
       "      <td>-0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>84</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>134</td>\n",
       "      <td>6</td>\n",
       "      <td>325</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.477143</td>\n",
       "      <td>-0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>84</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>133</td>\n",
       "      <td>6</td>\n",
       "      <td>326</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.465714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dep        date reg  tx_pos  tx_incid        TO  hosp  rea  rad  dchosp  \\\n",
       "56  01  2020-05-13  84    2.65      1.37  0.400716   139    8  315      88   \n",
       "57  01  2020-05-14  84    2.32      2.74  0.377460   137    8  318      88   \n",
       "58  01  2020-05-15  84    1.87      3.50  0.366726   135    7  323      89   \n",
       "59  01  2020-05-16  84    1.67      3.50  0.338104   134    6  325      90   \n",
       "60  01  2020-05-17  84    1.63      3.50  0.338104   133    6  326      90   \n",
       "\n",
       "    incid_hosp  incid_rea  incid_rad  incid_dchosp  pos  pos_7j   tx_test  \\\n",
       "56         6.0        0.0        4.0           0.0  9.0     9.0  1.934307   \n",
       "57         4.0        0.0        4.0           0.0  9.0    18.0  0.846715   \n",
       "58         4.0        0.0        5.0           1.0  5.0    23.0  0.534286   \n",
       "59         1.0        0.0        2.0           1.0  0.0    23.0  0.477143   \n",
       "60         1.0        0.0        1.0           0.0  0.0    23.0  0.465714   \n",
       "\n",
       "    tx_incid_IO  \n",
       "56     0.013605  \n",
       "57     0.000000  \n",
       "58    -0.014085  \n",
       "59    -0.014286  \n",
       "60     0.000000  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DPP2 for answering Question 2\n",
    "\n",
    "# monitor the trend of hospitals occupancy per department\n",
    "# Create a column with the result of ('incid_hosp' - 'incid_rad' - 'incid_dchosp')\n",
    "#  / ('hosp' + 'rea') = 'incid_IO'\n",
    "incid_hosp = np.array(df['incid_hosp'])\n",
    "incid_rad = np.array(df['incid_rad'])\n",
    "incid_dchosp = np.array(df['incid_dchosp'])\n",
    "hosp = np.array(df['hosp'])\n",
    "rea = np.array(df['rea'])\n",
    "\n",
    "# Avoid division by zero\n",
    "people_hospitalized = np.add(hosp, rea)\n",
    "\n",
    "# Replace 0 by 1 people to allow division \n",
    "ones = np.ones(np.shape(people_hospitalized), dtype=type(people_hospitalized))\n",
    "people_hospitalized = np.where(np.absolute(people_hospitalized) < 1, ones, people_hospitalized)\n",
    "\n",
    "tx_incid_IO = np.divide(np.subtract(incid_hosp, np.add(incid_rad, incid_dchosp)), people_hospitalized)\n",
    "df['tx_incid_IO'] = tx_incid_IO\n",
    "\n",
    "df['tx_incid_IO'] = df['tx_incid_IO'].fillna(0)  # Replace nan values by 0\n",
    "df['tx_incid_IO'].replace([np.inf, -np.inf], 0, inplace=True)  #Replace infinite value (inf) by 0\n",
    "\n",
    "# Check the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column label         type    nb uniq  rate uniq     nb nan   rate nan     nb inf   rate inf \n",
      "dep                object        101     0.11 %          0      0.0 %          0      0.0 % \n",
      "date               object        948     0.99 %          0      0.0 %          0      0.0 % \n",
      "reg                object         18     0.02 %          0      0.0 %          0      0.0 % \n",
      "tx_pos            float64       4581     4.78 %          0      0.0 %          0      0.0 % \n",
      "tx_incid          float64      50497    52.74 %          0      0.0 %          0      0.0 % \n",
      "TO                float64       3548     3.71 %          0      0.0 %          0      0.0 % \n",
      "hosp                int64       1548     1.62 %          0      0.0 %          0      0.0 % \n",
      "rea                 int64        402     0.42 %          0      0.0 %          0      0.0 % \n",
      "rad                 int64      16209    16.93 %          0      0.0 %          0      0.0 % \n",
      "dchosp              int64       4920     5.14 %          0      0.0 %          0      0.0 % \n",
      "incid_hosp        float64        203     0.21 %          0      0.0 %          0      0.0 % \n",
      "incid_rea         float64         57     0.06 %          0      0.0 %          0      0.0 % \n",
      "incid_rad         float64        165     0.17 %          0      0.0 %          0      0.0 % \n",
      "incid_dchosp      float64         41     0.04 %          0      0.0 %          0      0.0 % \n",
      "pos               float64       4331     4.52 %          0      0.0 %          0      0.0 % \n",
      "pos_7j            float64      13405     14.0 %          0      0.0 %          0      0.0 % \n",
      "tx_test           float64      91399    95.46 %          0      0.0 %          0      0.0 % \n",
      "tx_incid_IO       float64      13647    14.25 %          0      0.0 %          0      0.0 % \n"
     ]
    }
   ],
   "source": [
    "# Test values of the result\n",
    "display_columns_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data Post-processing DPP3\n",
    "\n",
    "Compute:\n",
    "- Rate of people admitted in intensive care over people hospitalized:\n",
    "   'incid_rea' / 'incid_hosp' = 'tx_rea'\n",
    "- Rate of deceases at hospital over people admitted in intensive care:\n",
    "   'incid_dchosp' / 'incid_rea' = 'tx_dchsop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep</th>\n",
       "      <th>date</th>\n",
       "      <th>reg</th>\n",
       "      <th>tx_pos</th>\n",
       "      <th>tx_incid</th>\n",
       "      <th>TO</th>\n",
       "      <th>hosp</th>\n",
       "      <th>rea</th>\n",
       "      <th>rad</th>\n",
       "      <th>dchosp</th>\n",
       "      <th>incid_hosp</th>\n",
       "      <th>incid_rea</th>\n",
       "      <th>incid_rad</th>\n",
       "      <th>incid_dchosp</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_7j</th>\n",
       "      <th>tx_test</th>\n",
       "      <th>tx_incid_IO</th>\n",
       "      <th>tx_rea</th>\n",
       "      <th>tx_dchosp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>84</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.400716</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>315</td>\n",
       "      <td>88</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.934307</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>84</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.377460</td>\n",
       "      <td>137</td>\n",
       "      <td>8</td>\n",
       "      <td>318</td>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>84</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>323</td>\n",
       "      <td>89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.534286</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>84</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>134</td>\n",
       "      <td>6</td>\n",
       "      <td>325</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.477143</td>\n",
       "      <td>-0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>84</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>133</td>\n",
       "      <td>6</td>\n",
       "      <td>326</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.465714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dep        date reg  tx_pos  tx_incid        TO  hosp  rea  rad  dchosp  \\\n",
       "56  01  2020-05-13  84    2.65      1.37  0.400716   139    8  315      88   \n",
       "57  01  2020-05-14  84    2.32      2.74  0.377460   137    8  318      88   \n",
       "58  01  2020-05-15  84    1.87      3.50  0.366726   135    7  323      89   \n",
       "59  01  2020-05-16  84    1.67      3.50  0.338104   134    6  325      90   \n",
       "60  01  2020-05-17  84    1.63      3.50  0.338104   133    6  326      90   \n",
       "\n",
       "    incid_hosp  incid_rea  incid_rad  incid_dchosp  pos  pos_7j   tx_test  \\\n",
       "56         6.0        0.0        4.0           0.0  9.0     9.0  1.934307   \n",
       "57         4.0        0.0        4.0           0.0  9.0    18.0  0.846715   \n",
       "58         4.0        0.0        5.0           1.0  5.0    23.0  0.534286   \n",
       "59         1.0        0.0        2.0           1.0  0.0    23.0  0.477143   \n",
       "60         1.0        0.0        1.0           0.0  0.0    23.0  0.465714   \n",
       "\n",
       "    tx_incid_IO  tx_rea  tx_dchosp  \n",
       "56     0.013605     0.0        0.0  \n",
       "57     0.000000     0.0        0.0  \n",
       "58    -0.014085     0.0        inf  \n",
       "59    -0.014286     0.0        inf  \n",
       "60     0.000000     0.0        0.0  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DPP3 for answering Question 3\n",
    "\n",
    "# Question 3-1\n",
    "# Compute Rate of people admitted in intensive care over people hospitalized\n",
    "df['tx_rea'] = df['incid_rea'].div(df['incid_hosp'])\n",
    "# Replace invalid data\n",
    "df = replace_invalid_data(df, 'tx_rea')\n",
    "\n",
    "# Question 3-2\n",
    "# Compute Rate of deceases at hospital over people admitted in intensive care\n",
    "df['tx_dchosp'] = df['incid_dchosp'].div(df['incid_rea'], fill_value=0.0)\n",
    "# Replace invalid data\n",
    "df = replace_invalid_data(df, 'tx_dchosp')\n",
    "\n",
    "# Check the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column label         type    nb uniq  rate uniq     nb nan   rate nan     nb inf   rate inf \n",
      "dep                object        101     0.11 %          0      0.0 %          0      0.0 % \n",
      "date               object        948     0.99 %          0      0.0 %          0      0.0 % \n",
      "reg                object         18     0.02 %          0      0.0 %          0      0.0 % \n",
      "tx_pos            float64       4581     4.78 %          0      0.0 %          0      0.0 % \n",
      "tx_incid          float64      50497    52.74 %          0      0.0 %          0      0.0 % \n",
      "TO                float64       3548     3.71 %          0      0.0 %          0      0.0 % \n",
      "hosp                int64       1548     1.62 %          0      0.0 %          0      0.0 % \n",
      "rea                 int64        402     0.42 %          0      0.0 %          0      0.0 % \n",
      "rad                 int64      16209    16.93 %          0      0.0 %          0      0.0 % \n",
      "dchosp              int64       4920     5.14 %          0      0.0 %          0      0.0 % \n",
      "incid_hosp        float64        203     0.21 %          0      0.0 %          0      0.0 % \n",
      "incid_rea         float64         57     0.06 %          0      0.0 %          0      0.0 % \n",
      "incid_rad         float64        165     0.17 %          0      0.0 %          0      0.0 % \n",
      "incid_dchosp      float64         41     0.04 %          0      0.0 %          0      0.0 % \n",
      "pos               float64       4331     4.52 %          0      0.0 %          0      0.0 % \n",
      "pos_7j            float64      13405     14.0 %          0      0.0 %          0      0.0 % \n",
      "tx_test           float64      91399    95.46 %          0      0.0 %          0      0.0 % \n",
      "tx_incid_IO       float64      13647    14.25 %          0      0.0 %          0      0.0 % \n",
      "tx_rea            float64       1250     1.31 %          0      0.0 %        638     0.67 % \n",
      "tx_dchosp         float64        444     0.46 %          0      0.0 %      12848    13.42 % \n"
     ]
    }
   ],
   "source": [
    "# Test values of the result\n",
    "display_columns_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data Post-processing DPP4\n",
    "Processing required for the display of values in time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep</th>\n",
       "      <th>date</th>\n",
       "      <th>reg</th>\n",
       "      <th>tx_pos</th>\n",
       "      <th>tx_incid</th>\n",
       "      <th>TO</th>\n",
       "      <th>hosp</th>\n",
       "      <th>rea</th>\n",
       "      <th>rad</th>\n",
       "      <th>dchosp</th>\n",
       "      <th>incid_hosp</th>\n",
       "      <th>incid_rea</th>\n",
       "      <th>incid_rad</th>\n",
       "      <th>incid_dchosp</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_7j</th>\n",
       "      <th>tx_test</th>\n",
       "      <th>tx_incid_IO</th>\n",
       "      <th>tx_rea</th>\n",
       "      <th>tx_dchosp</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>84</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.400716</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>315</td>\n",
       "      <td>88</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.934307</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>737922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>84</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.377460</td>\n",
       "      <td>137</td>\n",
       "      <td>8</td>\n",
       "      <td>318</td>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>737923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>84</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>323</td>\n",
       "      <td>89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.534286</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>737924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>84</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>134</td>\n",
       "      <td>6</td>\n",
       "      <td>325</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.477143</td>\n",
       "      <td>-0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>737925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>01</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>84</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>133</td>\n",
       "      <td>6</td>\n",
       "      <td>326</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.465714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>737926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dep        date reg  tx_pos  tx_incid        TO  hosp  rea  rad  dchosp  \\\n",
       "56  01  2020-05-13  84    2.65      1.37  0.400716   139    8  315      88   \n",
       "57  01  2020-05-14  84    2.32      2.74  0.377460   137    8  318      88   \n",
       "58  01  2020-05-15  84    1.87      3.50  0.366726   135    7  323      89   \n",
       "59  01  2020-05-16  84    1.67      3.50  0.338104   134    6  325      90   \n",
       "60  01  2020-05-17  84    1.63      3.50  0.338104   133    6  326      90   \n",
       "\n",
       "    incid_hosp  incid_rea  incid_rad  incid_dchosp  pos  pos_7j   tx_test  \\\n",
       "56         6.0        0.0        4.0           0.0  9.0     9.0  1.934307   \n",
       "57         4.0        0.0        4.0           0.0  9.0    18.0  0.846715   \n",
       "58         4.0        0.0        5.0           1.0  5.0    23.0  0.534286   \n",
       "59         1.0        0.0        2.0           1.0  0.0    23.0  0.477143   \n",
       "60         1.0        0.0        1.0           0.0  0.0    23.0  0.465714   \n",
       "\n",
       "    tx_incid_IO  tx_rea  tx_dchosp  timestamp  \n",
       "56     0.013605     0.0        0.0     737922  \n",
       "57     0.000000     0.0        0.0     737923  \n",
       "58    -0.014085     0.0        inf     737924  \n",
       "59    -0.014286     0.0        inf     737925  \n",
       "60     0.000000     0.0        0.0     737926  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP4\n",
    "\n",
    "# Add a timestamp column in df for being able to display data in time series \n",
    "#  and find most recent values per department.\n",
    "df['timestamp'] = get_timestamp_array(np.array(df['date']))\n",
    "\n",
    "# Check result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000026FEAE3D2C8>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP4\n",
    "\n",
    "# group the data set by dep and by timestamp to ease searching results by\n",
    "#  department and by time.\n",
    "\n",
    "df.groupby(['dep', 'timestamp'])  # If no dummy applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deps:\n",
      " ['01' '02' '03' '04' '05' '06' '07' '08' '09' '10' '11' '12' '13' '14'\n",
      " '15' '16' '17' '18' '19' '21' '22' '23' '24' '25' '26' '27' '28' '29'\n",
      " '2A' '2B' '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41'\n",
      " '42' '43' '44' '45' '46' '47' '48' '49' '50' '51' '52' '53' '54' '55'\n",
      " '56' '57' '58' '59' '60' '61' '62' '63' '64' '65' '66' '67' '68' '69'\n",
      " '70' '71' '72' '73' '74' '75' '76' '77' '78' '79' '80' '81' '82' '83'\n",
      " '84' '85' '86' '87' '88' '89' '90' '91' '92' '93' '94' '95' '971' '972'\n",
      " '973' '974' '976']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP4\n",
    "\n",
    "# Get the unique list of departments to get results for every department\n",
    "deps = pd.unique(df['dep'])\n",
    "\n",
    "# Check result\n",
    "print('deps:\\n', deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result in dep 01: {'date': '2022-12-16', 'value': 0.11546685673556666}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP4\n",
    "\n",
    "# I want to display computed values at the most recent date\n",
    "#  so for that purpose, I need to identify the last date and corresponding \n",
    "#  values for the selected category (column).\n",
    "\n",
    "def get_values_at_last_date(df, category, deps):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Provide values of the selected category at the last date available in\n",
    "         the dataframe, for every department.\n",
    "    INPUT\n",
    "        category is the name of the columns for which we want values at the \n",
    "         last date for every department\n",
    "    OUPUT\n",
    "        values is a dictionary with {dep: {'date': date, 'value': value of the\n",
    "         category at the stored date}}\n",
    "    '''\n",
    "\n",
    "    values = dict()\n",
    "\n",
    "    # format a dedicated list of data for the search\n",
    "    lst = [np.array(df['dep']),\n",
    "        np.array(df['date']),\n",
    "        np.array(df['timestamp']),\n",
    "        np.array(df[category])]\n",
    "\n",
    "    # Run over every department\n",
    "    for dep in deps:\n",
    "        time_ts = 0\n",
    "        id_max_date = 0\n",
    "        # run along the rows of the dataframe\n",
    "        for i, j in enumerate(lst[0]):\n",
    "            # When I met the selected department\n",
    "            #  and the timestamp is higher (ensure get finally the most\n",
    "            #  recent timestamp/date and related values of the category),\n",
    "            #  we stored date and value of the category in values, relatively\n",
    "            #  to the department. \n",
    "            if (j == dep) and (time_ts < lst[2][i]):\n",
    "                id_max_date = i\n",
    "                time_ts = lst[2][i]\n",
    "\n",
    "        values[dep] = {'date': lst[1][i], 'value': lst[3][i]}\n",
    "    return values\n",
    "\n",
    "# test the function\n",
    "test_tx = get_values_at_last_date(df, 'tx_test', deps)\n",
    "print('result in dep 01: {}'.format(test_tx['01'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP4\n",
    "\n",
    "# Convert result for visualization, I need to get values like\n",
    "#  date, {dep: values, ...}\n",
    "\n",
    "def format_values_for_vizu(dico_values, nb_decimal):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        format values for a vizualization on a map\n",
    "    INPUT\n",
    "        dico_values is a dictionary such {dep: {'date': date, 'value': value\n",
    "         of the category at the stored date}}\n",
    "    OUTPUT\n",
    "        series is a dictionary such as {date1: {depY: valueY, ...}, date2: {...}}\n",
    "    '''\n",
    "\n",
    "    series = dict()\n",
    "\n",
    "    dates = list()\n",
    "    for dep, j in dico_values.items():\n",
    "        date = j['date']\n",
    "        if date not in dates: # Create a sub-dictionary at every new date\n",
    "            dates.append(date)\n",
    "            series[date] = dict()\n",
    "        series[date][dep] = round(j['value'], nb_decimal)\n",
    "\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP4\n",
    "\n",
    "# I need to get all values of a categories along the time for a selected department\n",
    "\n",
    "def get_timeserie(category, dep, duration_week):\n",
    "    \n",
    "    # get dataframe the selecte category with time and departments\n",
    "    df_ = df[['dep', 'date', 'timestamp', category]]\n",
    "\n",
    "    # keep only rows with the selected dep\n",
    "    df_ = df_[df_['dep'] == dep]\n",
    "\n",
    "    # sort dataframe by descending timestamp (most recent at first)\n",
    "    df_.sort_values(by=['timestamp'], ascending=False, inplace=True)\n",
    "    \n",
    "    # get last timestamp (most recent date)\n",
    "    timestamp_max = df_['timestamp'].values[0]\n",
    "\n",
    "    # compute start of the time window\n",
    "    timestamp_min = timestamp_max - 7*duration_week  # unit here is the day\n",
    "                                                     # 7 days per week\n",
    "\n",
    "    # keep only dataframe on the required time stamp period\n",
    "    df_ = df_[df_['timestamp'] > timestamp_min]\n",
    "\n",
    "    # get expected values and related dates\n",
    "    dates = df_['date'].values.tolist()\n",
    "    values = df_[category].values.tolist()\n",
    "    # revers is for getting time flow from left to right\n",
    "\n",
    "    return list(reversed(dates)), list(reversed(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Data Post-processing DPP5\n",
    "\n",
    "Built a prediction model to give 'pos_7j' as target\n",
    "It may be tested to use dummy values and evaluate if it brings accuracy in the\n",
    " result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP5\n",
    "# \n",
    "# Try to get dummies on dep\n",
    "# Since there is a lot, wait and see.\n",
    "\n",
    "def dummy_data(df, cat):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        add dummy data to df removing the source of dummy\n",
    "    INPUT\n",
    "        df is the initial dataframe to work on\n",
    "        cat is the name of the category we want dummying\n",
    "    OUTPUT\n",
    "        df_dummy is the dataframe as copy of df but with dummy columns,\n",
    "         removing the source of dummy\n",
    "    '''\n",
    "    df_dummy = df.copy(deep=True)\n",
    "\n",
    "    # Create a new dataframe for preparing dummies from a copy of the \n",
    "    #  selected category \n",
    "    df_cat = pd.DataFrame([])\n",
    "    df_cat[cat] = np.array(df[cat])\n",
    "    print('shape df_cat:', df_cat.shape)\n",
    "\n",
    "    # Convert category values to just numbers 0 or 1 (dummy values) of category\n",
    "    df_dum = pd.get_dummies(df_cat[cat], dtype=int)\n",
    "    print('shape df_dum:', df_dum.shape)\n",
    "\n",
    "    for col in df_dum.columns:\n",
    "        df_dummy[col] = np.array(df_dum[col])\n",
    "    print('shape df_dummy:', df_dummy.shape)\n",
    "\n",
    "    # Drop the original category column from `df_dummy`\n",
    "    df_dummy.drop(columns=cat, inplace=True)\n",
    "    print('shape df_dummy drop:', df_dummy.shape)\n",
    "\n",
    "    # check number of duplicates\n",
    "    #  before trying removing duplicates\n",
    "    duplicates = df_dummy.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        df_dummy.drop_duplicates(keep='first', inplace=True)\n",
    "    print('shape df_dummy dupl:', df_dummy.shape)\n",
    "\n",
    "    # clean df_dummy from rows with full nan values\n",
    "    #  otherwise, at least the row is a nana row.\n",
    "    df_dummy.dropna(axis='index', how='all', inplace=True)\n",
    "    print('shape df_dummy dropna:', df_dummy.shape)\n",
    "\n",
    "    return df_dummy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP5\n",
    "# \n",
    "# Add dummy values of 'dep'\n",
    "\n",
    "# df = dummy_data(df, 'dep')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP5\n",
    "# Check the result\n",
    "\n",
    "# display_columns_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95748, 10)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP5\n",
    "# \n",
    "# Clean the dataframe dedicated to model \n",
    "\n",
    "# remove the date (str) and dep (str) not supported for\n",
    "#  the linear regression model.\n",
    "if 'dep' in df_lin.columns:\n",
    "    df_lin.drop(columns=['date', 'dep', 'reg', 'dchosp', 'rad', 'incid_rad'], inplace=True)  # without dummies\n",
    "else:\n",
    "    df_lin.drop(columns=['date', 'reg', 'dchosp', 'rad', 'incid_rad'], inplace=True)  # with dummies\n",
    "\n",
    "# Remove unexpected values from the dataframe dedicated to model\n",
    "df_lin.dropna(axis='index', how='any', inplace=True)\n",
    "\n",
    "# Check result of the action\n",
    "print(df_lin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP5\n",
    "\n",
    "# Build a model - define the target\n",
    "cat_response = 'pos_7j'\n",
    "cat_variables = np.array(df_lin.columns) # useless, included into the get X/y function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Spliting data into X/y ...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP5\n",
    "\n",
    "# Build a model - split the dataset into explanatory and response data sets\n",
    "\n",
    "def get_X_y(df: object, response:str):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Split df into exploratory X data and response y data\n",
    "    INPUT\n",
    "           df      : pandas dataframe\n",
    "           response : target variable\n",
    "    OUTPUT\n",
    "           X : A matrix holding all of the variables you want to consider\n",
    "                when predicting the response\n",
    "           y : the corresponding response vector\n",
    "    '''\n",
    "    # output\n",
    "    X, y = None, None\n",
    "\n",
    "    print(\" - Spliting data into X/y ...\")\n",
    "    # Get the Response var\n",
    "    if response in df.columns:\n",
    "        # try:\n",
    "        # Split into explanatory and response variables (1/2)\n",
    "        #  Get response variable\n",
    "        y = df[response]\n",
    "        df = df.drop(columns=[response])  # Remove pred_name from df\n",
    "        # except:\n",
    "        #     print(\"    CAUTION: Unable to get the response data in df\")\n",
    "        #     y = None\n",
    "    else:\n",
    "        print(\" - CAUTION: Unable to find the response in df\")\n",
    "        y = None\n",
    "\n",
    "    # Get the Exploratory vars\n",
    "    # try:\n",
    "    # Split into explanatory and response variables (2/2)\n",
    "    #  Get the input variables i.e. at this level just a copy of df\n",
    "    X = df.copy(deep=True)\n",
    "    # except:\n",
    "    #     print(\"    CAUTION: Unable to get the exploratory variables (X)\")\n",
    "    #     X = None\n",
    "\n",
    "    if X is None:\n",
    "        print(' - No X found')\n",
    "    if y is None:\n",
    "        print(' - No y found')\n",
    "\n",
    "    del df, response\n",
    "    return X, y\n",
    "\n",
    "# Split into Response y / Exploratory variables X\n",
    "X, y = get_X_y(df_lin, cat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Spliting data into X/y ...\n",
      "\tTraining ...\n",
      "\tModeling ...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# DPP5\n",
    "\n",
    "# Build a model - Get a trained model\n",
    "\n",
    "def get_model(X: object, y: object, testrate=.3):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Returns a linear prediction model according to train data,\n",
    "        and return r2 scores on train and test data.\n",
    "    INPUT\n",
    "           X          : explanatory variables object\n",
    "           y          : response variable object\n",
    "           testrate   : proportion of the dataset to include in\n",
    "                         the test split,between 0.0 and 1.0;\n",
    "                         default value = 0.3\n",
    "    OUTPUT\n",
    "            model : linear regression model object from sklearn\n",
    "            score : Merge of mean square error value between Train &\n",
    "                     Test data set according to the proposed model\n",
    "            list of X_train and y_train\n",
    "            list of X_test and y_test\n",
    "    '''\n",
    "    model, score = None, 0\n",
    "    Xtrain, Xtest, ytrain, ytest = None, None, None, None\n",
    "\n",
    "    # sub-variables\n",
    "    y_pred, msg, split = None, None, False\n",
    "    acc_score_train, acc_score_test = None, None\n",
    "    r2_score_train, r2_score_test = None, None\n",
    "    mdl_score_train, mdl_score_test = None, None\n",
    "    \n",
    "    print(\" - Spliting data into X/y ...\")\n",
    "    if (X is not None) and (y is not None):\n",
    "\n",
    "        # Split into train and test X/y data set\n",
    "        #  to establish the model and score it\n",
    "        print(\"\\tTraining ...\")\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X, y,\n",
    "                                                        test_size=testrate,\n",
    "                                                        random_state=42)\n",
    "        if (Xtrain is not None) and (Xtest is not None) and \\\n",
    "           (ytrain is not None) and (ytest is not None):\n",
    "            split = True\n",
    "\n",
    "        '''\n",
    "        # Work on dtype\n",
    "        recensed_type = {}\n",
    "        for var in X.columns:\n",
    "            tip = X[var].dtypes\n",
    "            if tip not in recensed_type:\n",
    "                recensed_type[tip] = 1\n",
    "            else:\n",
    "                recensed_type[tip] = recensed_type[tip] + 1\n",
    "        '''\n",
    "\n",
    "        # Establish model\n",
    "        print(\"\\tModeling ...\")\n",
    "        if split:\n",
    "\n",
    "            # Linear model from scikit-learn:\n",
    "            #  https://scikit-learn.org/stable/modules/linear_model.html#\n",
    "\n",
    "            # Linear Regression\n",
    "            model = LinearRegression()\n",
    "\n",
    "            # Linear model Lasso\n",
    "            # model = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "            # Ridge regression and classification\n",
    "            # model = linear_model.Ridge(alpha=.5)\n",
    "\n",
    "            # BayesianRidge()\n",
    "            # model = linear_model.BayesianRidge()\n",
    "\n",
    "            # LogisticRegression\n",
    "            # model = linear_model.LogisticRegression(random_state=0)\n",
    "            # very long -> not achieve\n",
    "\n",
    "            # generalized linear model TweedieRegressor\n",
    "            # model = linear_model.TweedieRegressor(power=1, alpha=0.5, link='log')\n",
    "            # Does not work!\n",
    "\n",
    "            # Stochastic Gradient Descent\n",
    "            # model = linear_model.SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "            # Does not provide good result\n",
    "\n",
    "            # model  = linear_model.Perceptron(tol=1e-3, random_state=0)\n",
    "            # Does not provide good result\n",
    "\n",
    "            # fit the model\n",
    "            model.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Test the model on test data\n",
    "            y_pred = model.predict(Xtest)\n",
    "        else:\n",
    "            y_pred = None\n",
    "            print(\"\\t - No Model defined\")\n",
    " \n",
    "    return model, [Xtrain, ytrain], [Xtest, ytest]\n",
    "\n",
    "\n",
    "# modeling\n",
    "model, Xy_train, Xy_test = get_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "Last step of this work consists in building data set for visualization\n",
    "\n",
    "Visualization required additional processing to get the appropriate values \n",
    " and provide these values in the appropriate format according to the \n",
    " visualization function.\n",
    " \n",
    "Concerning Question 1, 2 and 3, visualization is based on the display of\n",
    " results on a map of France, splited by department. Every department as a\n",
    " color according to the related value.\n",
    "\n",
    "Concerning Question 4, visualization consists in a plot of two curves, \n",
    " values of two parameters along the time.\n",
    " \n",
    "Concerning Question 5, visualization consists in display of score and \n",
    " coefficients of the model.\n",
    "\n",
    " In the python script, \n",
    "Graphical visualizations are displayed on pages of the default web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx_test_vizu:\n",
      " {'2022-12-16': {'01': 0.115, '02': 0.115, '03': 0.115, '04': 0.115, '05': 0.115, '06': 0.115, '07': 0.115, '08': 0.115, '09': 0.115, '10': 0.115, '11': 0.115, '12': 0.115, '13': 0.115, '14': 0.115, '15': 0.115, '16': 0.115, '17': 0.115, '18': 0.115, '19': 0.115, '21': 0.115, '22': 0.115, '23': 0.115, '24': 0.115, '25': 0.115, '26': 0.115, '27': 0.115, '28': 0.115, '29': 0.115, '2A': 0.115, '2B': 0.115, '30': 0.115, '31': 0.115, '32': 0.115, '33': 0.115, '34': 0.115, '35': 0.115, '36': 0.115, '37': 0.115, '38': 0.115, '39': 0.115, '40': 0.115, '41': 0.115, '42': 0.115, '43': 0.115, '44': 0.115, '45': 0.115, '46': 0.115, '47': 0.115, '48': 0.115, '49': 0.115, '50': 0.115, '51': 0.115, '52': 0.115, '53': 0.115, '54': 0.115, '55': 0.115, '56': 0.115, '57': 0.115, '58': 0.115, '59': 0.115, '60': 0.115, '61': 0.115, '62': 0.115, '63': 0.115, '64': 0.115, '65': 0.115, '66': 0.115, '67': 0.115, '68': 0.115, '69': 0.115, '70': 0.115, '71': 0.115, '72': 0.115, '73': 0.115, '74': 0.115, '75': 0.115, '76': 0.115, '77': 0.115, '78': 0.115, '79': 0.115, '80': 0.115, '81': 0.115, '82': 0.115, '83': 0.115, '84': 0.115, '85': 0.115, '86': 0.115, '87': 0.115, '88': 0.115, '89': 0.115, '90': 0.115, '91': 0.115, '92': 0.115, '93': 0.115, '94': 0.115, '95': 0.115, '971': 0.115, '972': 0.115, '973': 0.115, '974': 0.115, '976': 0.115}}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# QUESTION 1 - Data set for visualization \n",
    "\n",
    "# format for vizualization\n",
    "tx_test = get_values_at_last_date(df, 'tx_test', deps)\n",
    "# Get the selected data\n",
    "tx_test_vizu = format_values_for_vizu(tx_test, 3)\n",
    "# Data for visualization\n",
    "print('tx_test_vizu:\\n', tx_test_vizu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the results - Question 1:\n",
    "\n",
    "\tThe figures show that COVID-19 testing behaviour among people is rather \n",
    "\t homogeneous but low in mainland France while is 2 or 3 times more on \n",
    "\t islands in Guyane, Réunion and Mayotte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx_IO_vizu:\n",
      " {'2022-12-16': {'01': 0.0, '02': 0.0, '03': 0.0, '04': 0.0, '05': 0.0, '06': 0.0, '07': 0.0, '08': 0.0, '09': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '2A': 0.0, '2B': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 0.0, '36': 0.0, '37': 0.0, '38': 0.0, '39': 0.0, '40': 0.0, '41': 0.0, '42': 0.0, '43': 0.0, '44': 0.0, '45': 0.0, '46': 0.0, '47': 0.0, '48': 0.0, '49': 0.0, '50': 0.0, '51': 0.0, '52': 0.0, '53': 0.0, '54': 0.0, '55': 0.0, '56': 0.0, '57': 0.0, '58': 0.0, '59': 0.0, '60': 0.0, '61': 0.0, '62': 0.0, '63': 0.0, '64': 0.0, '65': 0.0, '66': 0.0, '67': 0.0, '68': 0.0, '69': 0.0, '70': 0.0, '71': 0.0, '72': 0.0, '73': 0.0, '74': 0.0, '75': 0.0, '76': 0.0, '77': 0.0, '78': 0.0, '79': 0.0, '80': 0.0, '81': 0.0, '82': 0.0, '83': 0.0, '84': 0.0, '85': 0.0, '86': 0.0, '87': 0.0, '88': 0.0, '89': 0.0, '90': 0.0, '91': 0.0, '92': 0.0, '93': 0.0, '94': 0.0, '95': 0.0, '971': 0.0, '972': 0.0, '973': 0.0, '974': 0.0, '976': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# QUESTION 2 - Data set for visualization\n",
    "\n",
    "# Get the selected values\n",
    "tx_incid_IO = get_values_at_last_date(df, 'tx_incid_IO', deps)\n",
    "# format for vizualization\n",
    "tx_IO_vizu = format_values_for_vizu(tx_incid_IO, 3)\n",
    "# Data for visualization\n",
    "print(\"tx_IO_vizu:\\n\", tx_IO_vizu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the results - Question 2:\n",
    "\n",
    "\tAlthough some departments see the number of patients at hospitals \n",
    "\tdecreasing, the majority of departments slightly increased their number \n",
    "\tof patients these last 24h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx_rea_vizu:\n",
      " {'2022-12-16': {'01': 0.0, '02': 0.0, '03': 0.0, '04': 0.0, '05': 0.0, '06': 0.0, '07': 0.0, '08': 0.0, '09': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '2A': 0.0, '2B': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 0.0, '36': 0.0, '37': 0.0, '38': 0.0, '39': 0.0, '40': 0.0, '41': 0.0, '42': 0.0, '43': 0.0, '44': 0.0, '45': 0.0, '46': 0.0, '47': 0.0, '48': 0.0, '49': 0.0, '50': 0.0, '51': 0.0, '52': 0.0, '53': 0.0, '54': 0.0, '55': 0.0, '56': 0.0, '57': 0.0, '58': 0.0, '59': 0.0, '60': 0.0, '61': 0.0, '62': 0.0, '63': 0.0, '64': 0.0, '65': 0.0, '66': 0.0, '67': 0.0, '68': 0.0, '69': 0.0, '70': 0.0, '71': 0.0, '72': 0.0, '73': 0.0, '74': 0.0, '75': 0.0, '76': 0.0, '77': 0.0, '78': 0.0, '79': 0.0, '80': 0.0, '81': 0.0, '82': 0.0, '83': 0.0, '84': 0.0, '85': 0.0, '86': 0.0, '87': 0.0, '88': 0.0, '89': 0.0, '90': 0.0, '91': 0.0, '92': 0.0, '93': 0.0, '94': 0.0, '95': 0.0, '971': 0.0, '972': 0.0, '973': 0.0, '974': 0.0, '976': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# QUESTION 3.1 - Data set for visualization\n",
    "\n",
    "# Get the selected values\n",
    "tx_rea = get_values_at_last_date(df, 'tx_rea', deps)\n",
    "# format for vizualization\n",
    "tx_rea_vizu = format_values_for_vizu(tx_rea, 3)\n",
    "# Data for visualization\n",
    "print(\"tx_rea_vizu:\\n\", tx_rea_vizu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx_rea_vizu:\n",
      " {'2022-12-16': {'01': 0.0, '02': 0.0, '03': 0.0, '04': 0.0, '05': 0.0, '06': 0.0, '07': 0.0, '08': 0.0, '09': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '2A': 0.0, '2B': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 0.0, '36': 0.0, '37': 0.0, '38': 0.0, '39': 0.0, '40': 0.0, '41': 0.0, '42': 0.0, '43': 0.0, '44': 0.0, '45': 0.0, '46': 0.0, '47': 0.0, '48': 0.0, '49': 0.0, '50': 0.0, '51': 0.0, '52': 0.0, '53': 0.0, '54': 0.0, '55': 0.0, '56': 0.0, '57': 0.0, '58': 0.0, '59': 0.0, '60': 0.0, '61': 0.0, '62': 0.0, '63': 0.0, '64': 0.0, '65': 0.0, '66': 0.0, '67': 0.0, '68': 0.0, '69': 0.0, '70': 0.0, '71': 0.0, '72': 0.0, '73': 0.0, '74': 0.0, '75': 0.0, '76': 0.0, '77': 0.0, '78': 0.0, '79': 0.0, '80': 0.0, '81': 0.0, '82': 0.0, '83': 0.0, '84': 0.0, '85': 0.0, '86': 0.0, '87': 0.0, '88': 0.0, '89': 0.0, '90': 0.0, '91': 0.0, '92': 0.0, '93': 0.0, '94': 0.0, '95': 0.0, '971': 0.0, '972': 0.0, '973': 0.0, '974': 0.0, '976': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# QUESTION 3.2 - Data set for visualization\n",
    "\n",
    "# Get the selected values\n",
    "tx_dchosp = get_values_at_last_date(df, 'tx_dchosp', deps)\n",
    "# format for vizualization\n",
    "tx_dchosp_vizu = format_values_for_vizu(tx_dchosp, 3)\n",
    "# Data for visualization\n",
    "print(\"tx_rea_vizu:\\n\", tx_dchosp_vizu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the results - Question 3:\n",
    "\n",
    "\tThe figures show there is some departments with significant level mainly in\n",
    "     region of Paris, the middle of France, in the South-west and the \n",
    "\t North-East, plus The Reunion.\n",
    "\n",
    "\tThe figures show a France with a level of decease due to COVID-19 globaly\n",
    "     low except in some departments of the South-west, North-East and in\n",
    "\t Guyane with rates between 1.5 and 3 times higher than elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_hosp:\n",
      " ['2022-07-02', '2022-07-03', '2022-07-04', '2022-07-05', '2022-07-06', '2022-07-07', '2022-07-08', '2022-07-09', '2022-07-10', '2022-07-11', '2022-07-12', '2022-07-13', '2022-07-14', '2022-07-15', '2022-07-16', '2022-07-17', '2022-07-18', '2022-07-19', '2022-07-20', '2022-07-21', '2022-07-22', '2022-07-23', '2022-07-24', '2022-07-25', '2022-07-26', '2022-07-27', '2022-07-28', '2022-07-29', '2022-07-30', '2022-07-31', '2022-08-01', '2022-08-02', '2022-08-03', '2022-08-04', '2022-08-05', '2022-08-06', '2022-08-07', '2022-08-08', '2022-08-09', '2022-08-10', '2022-08-11', '2022-08-12', '2022-08-13', '2022-08-14', '2022-08-15', '2022-08-16', '2022-08-17', '2022-08-18', '2022-08-19', '2022-08-20', '2022-08-21', '2022-08-22', '2022-08-23', '2022-08-24', '2022-08-25', '2022-08-26', '2022-08-27', '2022-08-28', '2022-08-29', '2022-08-30', '2022-08-31', '2022-09-01', '2022-09-02', '2022-09-03', '2022-09-04', '2022-09-05', '2022-09-06', '2022-09-07', '2022-09-08', '2022-09-09', '2022-09-10', '2022-09-11', '2022-09-12', '2022-09-13', '2022-09-14', '2022-09-15', '2022-09-16', '2022-09-17', '2022-09-18', '2022-09-19', '2022-09-20', '2022-09-21', '2022-09-22', '2022-09-23', '2022-09-24', '2022-09-25', '2022-09-26', '2022-09-27', '2022-09-28', '2022-09-29', '2022-09-30', '2022-10-01', '2022-10-02', '2022-10-03', '2022-10-04', '2022-10-05', '2022-10-06', '2022-10-07', '2022-10-08', '2022-10-09', '2022-10-10', '2022-10-11', '2022-10-12', '2022-10-13', '2022-10-14', '2022-10-15', '2022-10-16', '2022-10-17', '2022-10-18', '2022-10-19', '2022-10-20', '2022-10-21', '2022-10-22', '2022-10-23', '2022-10-24', '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', '2022-10-29', '2022-10-30', '2022-10-31', '2022-11-01', '2022-11-02', '2022-11-03', '2022-11-04', '2022-11-05', '2022-11-06', '2022-11-07', '2022-11-08', '2022-11-09', '2022-11-10', '2022-11-11', '2022-11-12', '2022-11-13', '2022-11-14', '2022-11-15', '2022-11-16', '2022-11-17', '2022-11-18', '2022-11-19', '2022-11-20', '2022-11-21', '2022-11-22', '2022-11-23', '2022-11-24', '2022-11-25', '2022-11-26', '2022-11-27', '2022-11-28', '2022-11-29', '2022-11-30', '2022-12-01', '2022-12-02', '2022-12-03', '2022-12-04', '2022-12-05', '2022-12-06', '2022-12-07', '2022-12-08', '2022-12-09', '2022-12-10', '2022-12-11', '2022-12-12', '2022-12-13', '2022-12-14', '2022-12-15', '2022-12-16']\n",
      "values_hosp:\n",
      " [265, 262, 273, 276, 280, 267, 277, 279, 279, 314, 319, 330, 347, 346, 354, 354, 351, 364, 345, 345, 339, 336, 336, 319, 328, 326, 322, 326, 315, 316, 308, 311, 237, 244, 245, 237, 237, 245, 251, 247, 249, 253, 253, 256, 257, 264, 258, 264, 240, 237, 238, 238, 238, 235, 228, 217, 215, 212, 209, 220, 227, 233, 237, 235, 234, 238, 233, 234, 237, 238, 239, 239, 237, 231, 235, 239, 211, 211, 211, 213, 211, 211, 213, 208, 197, 197, 211, 212, 221, 241, 238, 243, 243, 253, 272, 264, 255, 255, 254, 254, 253, 224, 217, 213, 212, 212, 212, 214, 224, 211, 207, 209, 209, 209, 211, 201, 203, 206, 201, 204, 204, 215, 221, 205, 205, 215, 212, 216, 222, 231, 229, 235, 236, 236, 236, 244, 248, 235, 249, 246, 246, 246, 250, 249, 254, 255, 257, 265, 265, 266, 293, 285, 291, 301, 301, 305, 313, 301, 305, 309, 342, 339, 339, 328, 335, 352, 370, 371]\n",
      "values_intensive:\n",
      " [20, 20, 18, 17, 24, 26, 32, 36, 36, 51, 52, 53, 52, 54, 54, 54, 56, 63, 51, 59, 54, 54, 54, 44, 44, 41, 40, 40, 38, 37, 35, 36, 22, 27, 27, 23, 23, 22, 22, 19, 20, 19, 19, 19, 20, 25, 26, 29, 19, 19, 19, 16, 14, 14, 14, 15, 15, 15, 15, 22, 23, 23, 25, 25, 24, 24, 19, 22, 22, 21, 21, 21, 20, 23, 23, 23, 11, 11, 11, 14, 13, 11, 13, 9, 9, 9, 10, 9, 15, 17, 15, 15, 15, 14, 15, 15, 12, 14, 14, 14, 15, 12, 13, 16, 15, 15, 15, 15, 16, 12, 14, 13, 13, 13, 14, 14, 14, 14, 18, 18, 18, 20, 20, 14, 13, 12, 12, 12, 12, 13, 11, 10, 9, 9, 9, 14, 15, 13, 16, 19, 19, 19, 18, 20, 22, 21, 22, 23, 23, 22, 23, 18, 20, 22, 21, 22, 24, 25, 26, 34, 36, 36, 36, 31, 36, 34, 37, 40]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# QUESTION 4 - Data set for visualization\n",
    "\n",
    "dates_hosp, values_hosp = get_timeserie('hosp', '31', 6*4)\n",
    "dates_intensive, values_intensive = get_timeserie('rea', '31', 6*4)\n",
    "\n",
    "# Data for visualization\n",
    "print(\"dates_hosp:\\n\", dates_hosp)\n",
    "print(\"values_hosp:\\n\", values_hosp)\n",
    "print(\"values_intensive:\\n\", values_intensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the results - Question 4:\n",
    "\n",
    "\tIn my department of Haute-Garonne, the figures show a continuous increase\n",
    "     of hospitalization since beginning of November: the level was multiplied\n",
    " \t by 1.5 in a month.\n",
    "\tIn parallel, the number of deceases at the hospital remains increased in \n",
    "\t the same period with a level multiplied by 3 in a month, reaching at last\n",
    "     40 deceases per day due to COVID-19. This number remains in the result of \n",
    "\t these last months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "- Model score (train): 0.881512098436752\n",
      "- Model score (test): 0.8738613401903677\n",
      "- r2 score (train): 0.881512098436752\n",
      "- r2 score (test): 0.8738613401903677\n",
      "model's score:  0.881512098436752\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# QUESTION 5 - Display performance of the model\n",
    "\n",
    "def get_model_performance(model, Xy_train, Xy_test, Xy):\n",
    "\n",
    "    Xtrain, ytrain = Xy_train\n",
    "    Xtest, ytest = Xy_test\n",
    "    X, y = Xy\n",
    "\n",
    "\n",
    "    # Evaluate this model by gettings metrics with a model by Regression\n",
    "    print(\"Metrics:\")\n",
    "    \n",
    "    # Get the model's score\n",
    "    # Return the coefficient of determination of the prediction\n",
    "    mdl_score_train = model.score(Xtrain, ytrain)\n",
    "    print(\"- Model score (train):\", mdl_score_train)\n",
    "    mdl_score_test = model.score(Xtest, ytest)\n",
    "    print(\"- Model score (test):\", mdl_score_test)\n",
    "\n",
    "    # Accuracy_score (https://scikit-learn.org/stable/modules/\n",
    "    # generated/sklearn.metrics.accuracy_score.html)\n",
    "    # Confusion matrix (https://scikit-learn.org/stable/modules/\n",
    "    # generated/sklearn.metrics.confusion_matrix.html)\n",
    "    #  not appropriate for my purpose\n",
    "    # Common pitfalls (https://scikit-learn.org/stable/common_\n",
    "    #  pitfalls.html): mean_sqaured_error and r2_score\n",
    "\n",
    "    # According to https://stackoverflow.com/questions/37367405/\n",
    "    #  python-scikit-learn-cant-handle-mix-of-multiclass-and-continuous\n",
    "    # ... Accuracy score is only for classification problems\n",
    "    # acc_score_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    # acc_score_test = accuracy_score(y_test, model.predict(X_test))\n",
    "    # if debug: print(\"    - acc_score_train:\", acc_score_train)\n",
    "    # if debug: print(\"    - acc_score_test:\", acc_score_test)\n",
    "\n",
    "    # always according to https://stackoverflow.com/questions/37367405/\n",
    "    #  python-scikit-learn-cant-handle-mix-of-multiclass-and-continuous\n",
    "    # For regression problems, use: R2 Score, MSE (Mean Squared Error),\n",
    "    # RMSE (Root Mean Squared Error).\n",
    "    r2_score_train = r2_score(ytrain, model.predict(Xtrain))\n",
    "    r2_score_test = r2_score(ytest, model.predict(Xtest))\n",
    "    print(\"- r2 score (train):\", r2_score_train)\n",
    "    print(\"- r2 score (test):\", r2_score_test)\n",
    "\n",
    "    score = r2_score_train\n",
    "    print(\"model's score: \", score)\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Check performance\n",
    "score = get_model_performance(model, Xy_train, Xy_test, [X, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Define impact of categories on the model:\n",
      "\t         est_int       coefs   abs_coefs\n",
      "2            TO -966.678578  966.678578\n",
      "7  incid_dchosp -167.490157  167.490157\n",
      "6     incid_rea  -75.851722   75.851722\n",
      "0        tx_pos  -28.293308   28.293308\n",
      "5    incid_hosp   10.533020   10.533020\n",
      "4           rea    9.841827    9.841827\n",
      "3          hosp    4.663104    4.663104\n",
      "8           pos    4.059020    4.059020\n",
      "1      tx_incid    3.190276    3.190276\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# QUESTION 5 - Display level of importance of every category on the model\n",
    "\n",
    "def coef_weights(model, X_train) -> object:\n",
    "    '''\n",
    "    returns a dataframe with coefficients of the model\n",
    "     (real and absolute values) sorted in the descending order\n",
    "     of the absolute values\n",
    "\n",
    "    input:\n",
    "           model     : model for which we are looking coefficients\n",
    "           X_train   : the training data\n",
    "    output:\n",
    "            coefs_df : dataframe with model's coefficients; that can be\n",
    "                        used to understand the most influential coefficients\n",
    "                        in a linear model by providing the coefficient\n",
    "                        estimates along with the name of the variable\n",
    "                        attached to the coefficient.\n",
    "    '''\n",
    "    # function: get model's coefficients\n",
    "\n",
    "    coefs_df = pd.DataFrame()\n",
    "    # Get name of every column in front  of its coefficients\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    # get coefficients of the linear model\n",
    "    coefs_df['coefs'] = model.coef_\n",
    "    # get absolute value of these coefficients\n",
    "    coefs_df['abs_coefs'] = np.abs(model.coef_)\n",
    "    # Sort coefficient by descending order\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "\n",
    "    del model, X_train\n",
    "    return coefs_df\n",
    "\n",
    "\n",
    "print('  > Define impact of categories on the model:')\n",
    "coef_df = None\n",
    "\n",
    "# Compute coefficient of weight on every category for this model\n",
    "coef_df = coef_weights(model, Xy_train[0])  # Xy_train = [Xtrain, ytrain]\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print('\\t', coef_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the results - Question 5:\n",
    "\n",
    "   The model to predict COVID-19 positive cases per week gives rather good\n",
    "   result\n",
    "    with a global score of 0.88.\n",
    "   Analysis of the contribution of every parameters shows that the result is\n",
    "    mainly linked with the Occupancy rate (TO) which is actuall rather \n",
    "\tconsequence of the prediction.\n",
    "   It shows a high level a correlation between the number of positive cases\n",
    "    and the amount of work in the hospitals despite the vaccination campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINDINGS\n",
    "\n",
    "About 6% of data were removed from the initial data set due to missing \n",
    " values. It concerns mainly first set of data at the beginning of the data \n",
    " collection. Indeed, method, measure, collection and presentation of data \n",
    " change in time before getting the current format of data.\n",
    " Nevertheless, we benefit from a huge amount of valid data for the analysis.\n",
    " \n",
    "Computation of some rates raised the problem of division by 0. While taking \n",
    " about group of people and with the will of showing result for every \n",
    " department, I replace 0 by 1 when necessary.\n",
    " \n",
    "I also face infinite values; then I replaced with infinite values by maximum\n",
    " numerical values of the serie, in order to be reasonable realistic and show\n",
    " result.\n",
    "\n",
    "Although testing several type of models, I kept the Linear Regression which\n",
    " give rather good results with an implementation rather simple. \n",
    "I wonder if some other type of models could be more suitable in this case.\n",
    "\n",
    "Display of maps and plots from the Notebook was not easy due to difficulties\n",
    "of installation of additional libraries and other things required to make it \n",
    "run correctly; all these installations were not possible on my profressional\n",
    "laptop to safety policy of my company.\n",
    "Nevertheless, display of these graph is possible with the python code."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
